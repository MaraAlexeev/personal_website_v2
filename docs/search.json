[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Who am I?\nMy name is Mara Alexeev. I currently live in Jersey City, New Jersey, but I grew up on a farm in central Iowa. In fourth grade I was in love with space and wanted to be a part time astronaut and part time farmer.\nIn the summer of 2022, I finished a masters in Biomedical Informatics at Harvard Medical School and a fellowship in Clinical Informatics at Boston Children’s Hospital. My primary medical specialty is Pediatrics.\nCurrently, I am the Director of Clinical Informatics at a health tech start up called Dandelion Health.\nI love learning human and computer languages. I’ve had a long love affair with Russian and German, and recently became interested in American Sign Language (and also the Russian Manual Alphabet!) and thinking about learning Norwegian. On the computer front, I’m always learning more Python, R, and SQL. I enjoy data visualization and reproducible analysis and research.\nInterested in connecting or collaborating? Send me a message on Linkedin!\n\n\n\n\n\nMara at the Tandy, age 3"
  },
  {
    "objectID": "posts/2021-05-25-running-my-first-r-workshop/index.html",
    "href": "posts/2021-05-25-running-my-first-r-workshop/index.html",
    "title": "Running My First R Workshop",
    "section": "",
    "text": "Clinical Informatics Conference 2021\nI attended the virtual Clinical Informatics Conference last week, and I also did a workshop on R for Clinical Informatics. This was the first time I had ever developed material for a workshop and run a workshop. It was a solo operation, but fortunately I had some great support from my fellowship program beforehand to get prepared.\nAll the materials can be found here. Note the RStudio Cloud workspace has been turned off, but all the materials are available on that Github repo.\n\n\nPrior Experience\nI started learning R in Spring of 2019. I started reading R for Data Science and found the #rstats twitter world. Fall of 2019 I went to my first conference about R, R/Medicine, which I now help plan! At that 2019 R/Medicine conference I went to my first workshop—R Markdown for Medicine, which was taught by the amazing Dr. Alison Hill.\n\n\nPlanning\nI spent rough two entire work days planning the submission to CIC in January 2021. This includes all the false start ideas I had before settling on the workshop idea. This including a skeleton of some of the actual material I ended up using.\nMy final submission and eventual project used simulated data that one might have while doing a Quality Improvement project to show how one could use R for the entire process or pieces of it.\nI then spent 1.5 days creating the first draft of the material in mid-April. I presented my draft to my fellowship group, got amazing feedback, and then spent another 1.5 days incorporating the feedback for that. I was able to ignore it for a few days, and then polished off the final slides that had to be submitted in a PDF format for the pre-conference materials. I then spent about another day polishing off html slides to include some nicer formatting and some ggplots, finished the materials for the attendees to do, setting everything up on RStudio Cloud, and pushing everything to a nice Github page.\n\n\nWorkshop\nThe workshop was held on zoom. Let me just say how thankful I am to the few people who kept their cameras on and/or who spoke. It is such wonderful feedback in the video conference isolation chamber to hear from people so you can help and adapt during the conference.\nI was initially worried that the material I had and the amount was too little. I think this is unlikely to be true for me in the future! I had 100 ideas I wanted to share, but fortunately after doing a dry run with folks to my program, I was able to really trim it down to the core basics I wanted to share with some accessible extras of more advanced features.\nRStudio Cloud worked great, and no one had technical issues that they shared with me.\nOne funny thing that happened as we were walking through the examples in the prepared .Rmd, is that I discussed packages and libraries, but I forgot to tell people to run that code chunk! Fortunately, someone spoke up relatively quickly and I could tell folks to do that. As an instructor, it is amazing how quickly you can forget how very not intutive the basics of coding are.\nI believe about 50 people registered for the workshop and 25 were there for any portion, and then had a solid base of 20 people for most of the workshop.\nI did a survey about people’s experience with programming and R:\n\nAbout 50% of people had every programmed before in ANY language\n40% of people had ever used R before\n40% had used RStudio before (presumably the same 40%?)\n\nPeople’s goals for the workshop ranged from seeing what R was to learning how to do specific types of plots in ggplot for their quality improvement projects.\n\n\nAfterthoughts\nI loved it. I had a great time, and I learned a ton about how to present. It was great to hear questions from folks because it forced me to give very simple, clear responses which sometimes improved my understanding.\nPeople asked really great questions, some of which I didn’t know the answer at the time. For example, is RStudio Cloud HIPPA compliant. Answer: No! But there are other services that are that you could use R and RStudio on.\n\n\nDo better next time\nI took notes on what to do differently next time!\n\nHave a better way to give my contact information (on the Github page)\nMove the slides about how to knit to the point in the workshop that people will need it\nAdd more real world examples of how R is or could be used in medicine\nFigure out how folks use R and RStudio in HIPAA compliant ways\nGive post-workshop tips\n\nHow to download R and RStudio\nMake a RStudio project\nClone a Github repo\nStart a Github issue\n\nShow survey results"
  },
  {
    "objectID": "posts/2021-12-05-pedestrian-nightmare/index.html",
    "href": "posts/2021-12-05-pedestrian-nightmare/index.html",
    "title": "Pedestrian Nightmare",
    "section": "",
    "text": "Big parenting fears\nOne of my biggest fears as a parent is the threat of cars to the well-being of my children. And unlike other lurking parenting fears, this one is upsetting because it is a fairly rational fear based on the causes of death and injury to children in and out of vehicles.\nI hope to learn a bit more about how my own community could make streets safer and better for folks, so putting this here as a promise to myself.\n\n\n\n\n\nNightmare interaction of pedestrian areas and cars."
  },
  {
    "objectID": "posts/2022-10-30-the-prize/index.html",
    "href": "posts/2022-10-30-the-prize/index.html",
    "title": "The Prize",
    "section": "",
    "text": "The Prize\nI read The Prize by Daniel Yergin two plus years ago while in the haze of a new baby and starting a masters and doing a fellowship, so a book report written at that time would probably be a patchy effort at best. Thus a book report written two years later is most certainly entirely suspect. However, I loved the book, and I now recommend it to anyone who will let me get to the point in a conversation where we are talking books.\n\n\nSelected unpolished thoughts\n\nhow much energy enables our modern life\nhow much oil is a national security concern\nwhy oil geography is wrapped up in wars\nthat the Nazis and Japanese Empire lost WWII in part because of energy insufficiency\nhow amazing the logistics of oil refinement and distribution are\nhow the needs of the oil industry created the most complicated and capable organizations in the world because they had the thing everyone wanted everywhere and there was a ton of competition\noil is power, figuratively\nmaybe most people don’t understand at all how important oil is because I certainly didn’t before I read the book\nhow crazy the personalities were in the history of oil and how different strategies worked or did not work\nunderstanding nationalism more in the context of industrial ‘imperialism’\nimportance of human capital (an oil poor country like they Netherlands is a business powerhouse because it has talented people working on them problem) and knowledge infrastructure\nif some countries were able to get (and were not actively thwarted by external forces) themselves together they could be much better, bigger world players\nrelated to that, how delicate the policies and relationships can be between companies and the country they are operating in (eg Mexico getting angry and nationalizing the oil, but if that happens then no company will ever want to go there again and then they won’t be able to profit from their natural resources). Trump picking Rex Tiller as Secretary of State made much more sense after reading this book because I realized how much an Oil Company is like a country with little enclaves in many countries and assets in many (pipelines) and a non military “navy”.\nthe amazing pressure oil companies self imposed on themselves to decrease drilling and improve well conditions and the terrible conditions that were created by competing operators drilling too much into fields and causing the fields to fail prematurely because of destruction of the favorable conditions for extraction\nthe amazing technology that came out of the necessities of the oil industry\n\nQuestions I still don’t understand:\n\nwhy hydrocarbon companies aren’t leading the charge into nuclear energy?\nwho benefits from the public sentiment of “big bad oil” when literally everyone in the US is using their products in many parts of their lives\nwith the oil spills that have happened, is this a lot or is this not a lot (the process sounds completely terrifying) given the complexity of the process and inherent danger in a operation of such scale with hydrocarbons and involving so many natural factors (eg the oil field, ice bergs, hurricanes)\nwhy so many of the countries with this amazing resource are so poorly managed or have such repressive regimens (this is addressed but probably needs its own book!)\n\n\n\nFuture reading\nNext on my reading lists will be some of Yergin’s subsequent books. I will try to do better note take for future posts."
  },
  {
    "objectID": "posts/2022-11-12-cod-liver-in-nine-acts/index.html",
    "href": "posts/2022-11-12-cod-liver-in-nine-acts/index.html",
    "title": "Cod Liver in Nine Acts",
    "section": "",
    "text": "Family visited recently and left us with nine cans of Icelandic Cod Liver. Why nine you ask? Well they had a box of twelve sent ahead of their visit and ate three of them while staying with us.\n\n\n\n\n\n\n\n\n\nI texted a picture of my undeserved hepatic lode of Northern Atlantic goodness to med school friends and promised culinary updates in my pursuit of full turn over of the cupboard inventory. Well, it is just too good of a joke to not take seriously. The tin also is a bit inspirational with the brand name “iCan”.\nI’m not a spicy food fanatic, but other than that I am try to be game for trying something at least once.\nThe process of getting these fish livers to me in tidy little tins is probably worthy of its own write up, but alas we will have to settle with Mara reviewing the end product.\nACT I\nI opened the can up and it reminded me of cat food. Cat food I would be happy to feed to my hypothetical cat, but cat food nonetheless.\n\n\n\n\n\n\n\n\n\nThe first recipe was just the product of reviewing a few Google hits and synthesizing them into something that I had the ingredients for. Hard to even call it a recipe since it was so easy to do.\nCod liver on toast\n\nCan of cod liver, drained then mashed with fork\nTwo hard boiled eggs, sliced\nChopped chives, 1 teaspoon combined with cod liver, and 2 teaspoon reserved for garnish\nSqueeze of lemon juice into mashed cod liver\nToast, buttered\nSalt to taste\n\nTop toast with mashed cod liver. Add a slice of egg and top with chives. Enjoy!\n\n\n\n\n\n\n\n\n\nReview – Totally fine! Good even. And looked fancy. I think a high end butter would elevate it. I happened to have a fresh loaf of sourdough bread at home, and that was a very nice combo. Would consider serving this at a party like a Russian style New Year’s Eve party with lots of small appetizers. Probably would not eat a ton of these, but certainly an interesting dish with good texture.\n\n\n\n\n\n\n\n\n\nACT II-IX\nTo be continued…"
  },
  {
    "objectID": "posts/2023-02-26-a-sticky-bun-but-not-every-day/index.html",
    "href": "posts/2023-02-26-a-sticky-bun-but-not-every-day/index.html",
    "title": "A sticky bun, but not every day",
    "section": "",
    "text": "In the summer of 2020 we moved to Brookline, MA. Our routine immediately developed that we would do daycare drop off and then stop by Temptations Cafe (Hi Nassib!!) We particularly enjoyed their sticky buns, but it took us about 128 trips to the cafe on 108 dates to recognize the pattern of when sticky buns were available or not.\nHere I have made a github style waffle plot, that I believe makes the pattern of when sticky buns are available clearer. We finally noticed what the pattern was in October, when the days sticky buns were available increased.\nI copied the gh_waffle function from Matti Vuorre’s blog post with some minor modifications."
  },
  {
    "objectID": "posts/2023-03-05-personal-website-version-2/index.html",
    "href": "posts/2023-03-05-personal-website-version-2/index.html",
    "title": "Personal Website Version 2.0",
    "section": "",
    "text": "I wanted to move away from my “original” blogdown method of blogging because I am really enthused about how great Quarto is. My blogdown project had accumulated so much code debris over the years because I started it when I was first learning to code, that it seemed easier to just take the posts and migrate them to a new Quarto Website + Blog than correcting all the mistakes accumulated over 4 years. I am initially going to post this on Github Pages, but once I have migrated content from my old site, I will reassign this repo to my Netlify account to deploy to my personalized domain.\nThree things I wanted out of the new website:\n\nMake writing posts easy. Quarto does not have an add-in (yet) like Blogdown does to create a new blog post. So I leaned very, very heavily on Mark Edney’s R-Blogger’s post on how to make a handy Shiny app to take the thinking out of setting up each blog post. The rough part of being just excited enough to blog, but with huge time constraints is that I might go months in between posting and inevitably forget things and it frustrates me.\nHave a website plus a blog so the Quarto Website + Blog was a great combo idea that I was able to execute with help from a post by Samantha Csik.\nEnable discussions on my blog. I don’t think I have much traffic on my blog, but I know a few people have used things I have written because when I was Googling myself I found someone thanking me in their blog post about something I had had to troubleshoot in my blog and of course then blogged about it. Last fall I saw a cool method called giscus, so will use that.\n\n\n\nFor setting up the Shiny App, the only major change I did was to make a multi-select option for categories for my blog post template from Mark’s original work. This is nice because it helps me make sure I am not duplicating categories (eg Medicine and medicine) because categories are case sensitive. I also added a data-modified section to my template because I like to capture when I update a post. Also, I love the YAML template including draft = 'true' to harder to accidentally post a draft version of your post.\nHere’s the whole app below.\n\n\nCode\n# Source https://www.r-bloggers.com/2022/08/creating-posts-for-quarto-blog/\n#\n\nlibrary(shiny)\nlibrary(miniUI)\n\nQGadget <- function() {....}\n\nui <- miniUI::miniPage(\n  miniUI::gadgetTitleBar(\"Quarto Blog Post\"),\n  miniUI::miniContentPanel(\n    shiny::textInput(\"title\", \"Title\", placeholder = \"Post Title\"),\n    shiny::selectInput(\"categories\", \"Categories\", \n                       choices = list(\"How-to\", \n                                      \"R\", \"Python\", \"Quarto\",\n                                      \"Medicine\", \n                                      \"Family Life\", \"Cooking\"),\n                       multiple = TRUE)\n\n  )\n)\n\nserver <- function(input, output, session) {\n  \n  shiny::observeEvent(input$done, {\n    Blog_post(input$title, input$categories)\n    stopApp(\"Post Created\")\n  })\n}\n\nshiny::runGadget(ui, server, viewer = shiny::dialogViewer(\"Quarto Blog Post\"))\n\nBlog_post <- function(title, categories){\n  data <- list(title = title,\n               author = \"'Mara Alexeev'\",\n               date = Sys.Date(),\n               date_modified = \"'`r Sys.Date()`'\",\n               categories = categories,\n                 \n               draft = 'true',\n               description = \"''\",\n               image = \"''\",\n               archives = format(date, \"%Y/%m\"),\n               toc = 'false',\n               fold = \"true\",\n               tools = 'true',\n               link =  'false')\n  \n  Template <- '---\ntitle: {{title}}\nauthor: {{author}}\ndate: {{date}}\ndate-modified: {{date_modified}}\ncategories: [{{categories}}]\ndraft: {{draft}}\ndescription: {{description}}\nimage: {{image}}\narchives:\n  - {{archives}}\ntoc: {{toc}}\n\nformat:\n  html:\n    code-fold: {{fold}}\n    code-tools: {{tools}}\n---\n\n# Introduction\n\n# Conclusion\n\n'\n  \n  dir.create(paste0(\"./posts/\",data$date, \"-\", title))\n  writeLines(whisker::whisker.render(Template, data), paste0(\"./posts/\",data$date, \"-\", title, \"/index.qmd\"))\n  file.edit(paste0(\"./posts/\",data$date, \"-\", title, \"/index.qmd\"))\n}\n\n\n\n\n\nSamantha points out that a Quarto Blog is just a special point of a Quarto website. I actually got a little concerned about using Quarto as my blog because the directions of how to set up the individual posts had a lot of steps that I was worried I would not be able to do consistently over time. That’s when I thought to write a script to do it for me, and instead was saved several hours of work by Mark’s post.\n\n\n\nOkay, so this is the main thrust of this post: Giscus. Which has painfully cute name. I was actually able to set it up on a test Quarto Book project, but of course that was months ago, and I can’t remember the process because I didn’t write it down! So for myself and for everyone else, here I go!\nFirst, why did I choose giscus? I loved that it supported multiple languages (human languages because I sometimes blog about languages that don’t use the Latin alphabet), it has some math notation ability, and it is open source and has a great github page.\n\n\n\n\nYou have to add giscus as an app on Github.\nDepending on your settings, you additionally may need to add the repo of interest to you configuration settings on giscus.\nEnable discussions on your repo (settings -> features -> discussions).\nGo to giscus.app and follow instructions there and it will give you some good information like repo-id which you will need to put in your _quarto.yml.\nTake the information from the giscus.app and update your _quarto.yml to include information about the repo, giscus, and some ids. Unfortunately, it is not formatted the way you need to put it into the _quarto.yml.\n\n  comments: \n    giscus:\n      repo: MaraAlexeev/personal_website_v2\n      repo-id: FAKE_REPO_ID #Get this from giscus.app\n      category: General\n      category-id: FAKE_CATEGORY_ID #Get this from giscus.app\n      mapping: title #pathname was very gross format\n      reactions-enabled: TRUE\n      input-position: bottom\n      theme: light\n\nFor pages you don’t want to have comments on put in the yaml header of that page comments: false. I do this for my blog post listing page and my about page."
  },
  {
    "objectID": "posts/2023-03-12-updates-to-shiny-app-for-creating-blog-posts/index.html",
    "href": "posts/2023-03-12-updates-to-shiny-app-for-creating-blog-posts/index.html",
    "title": "Updates to Shiny App for Creating a Blog Posts",
    "section": "",
    "text": "Updates on Shiny App\nLast week I wrote about how I found someone else who had written a Shiny app to create blog posts with a small amount of manual input, like the title of the post, and the app would then create the necessary files for the Quarto website format and start the post with a predetermined template with the components you added into the Shiny app.\nThis weekend while I was transferring more posts over from my old website, I noticed a few annoying and related features.\nMy posts’s folders were named something like this 2023-01-01-This Test Post is Amazing, but then my URL paths when I rendered my website were awful looking like website.com/2023-01-01-This%20Test%20Post%20is%20Amazing. Also, if I tried to include some types of punctuation, like a colon, in my title, which is the source of the folder name and URL, it would break my Shiny app.\nSolution: I added a “slugifying” part to my Shiny App:\nslug = stringr::str_replace_all(stringr::str_to_lower(title), \"[^[:alnum:]]\", \"-\")\nNow the transformed version of the title, the slug, doesn’t have any punctuation except for dashes or capital letters, so now the URLs and folder names look much better. Also, my title can have “special” punctuation without breaking my Shiny app. The app was failing in writing file names, so while I don’t know exactly why that is, I do have a sense that file names often don’t like crazy characters.\nFinally, one more thing I need to do to improve my Shiny app is fix some directory issues. Currently I can only run my Shiny app when I highlight all the code and select run. If I try to run it from the console, it can’t find the correct directory to put the new post in. I suspect this has something to do with how the working directory is determined.\nUntil next time friends!"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Mara’s Blog",
    "section": "",
    "text": "Updates to Shiny App for Creating a Blog Posts\n\n\n\nQuarto\n\n\n\nImprove the slug!\n\n\n\nMara Alexeev\n\n\nMar 12, 2023\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nPersonal Website Version 2.0\n\n\n\nQuarto\n\n\nR\n\n\nHow-to\n\n\n\nBuilding a new Quarto website\n\n\n\nMara Alexeev\n\n\nMar 5, 2023\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nA sticky bun, but not every day\n\n\n\nR\n\n\nQuarto\n\n\nFamily Life\n\n\n\nSolving a cafe mystery\n\n\n\nMara Alexeev\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nCod Liver in Nine Acts\n\n\n\nCooking\n\n\n\nSo much cod liver\n\n\n\nMara Alexeev\n\n\nNov 12, 2022\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nThe Prize\n\n\n\nBook Review\n\n\n\nA book report, partially forgotten\n\n\n\nMara Alexeev\n\n\nOct 30, 2022\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nPedestrian Nightmare\n\n\n\nFamily Life\n\n\n\nDreaming about pedestrian first spaces\n\n\n\nMara Alexeev\n\n\nDec 5, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlt Responses to Give the God of Death\n\n\n\nR\n\n\nProject\n\n\n\nToday???\n\n\n\nMara Alexeev\n\n\nNov 8, 2021\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nRunning My First R Workshop\n\n\n\nR\n\n\n\nAnd thoughts for making it better!\n\n\n\nMara Alexeev\n\n\nMay 25, 2021\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021-11-08-alt-responses-to-give-the-god-of-death/index.html",
    "href": "posts/2021-11-08-alt-responses-to-give-the-god-of-death/index.html",
    "title": "Alt Responses to Give the God of Death",
    "section": "",
    "text": "“There is only one god and his name is death. And there is only one thing we say to death: Not today.”\n― Syrio Forel (Game of Thrones S1:Ep6: A golden crown)\n\nWhile Game of Thrones fans are fond of refusing the God of Death, Wikipedia has lots of data about people who did say: Ok, today is the day.\n\n\n\n\nInspiration\nIn July 2020, my husband presented me with two tweets about change of the average age of death over time (tweet 1 and tweet 2) and challenged me to make some cooler graphs.\n\n\n\n\n\n\n\n\n\n\n\n\nMotivations\nWith this post, I want to do three things:\n\nSee if I could make more engaging graphs than the original twitter post using R\nLearn to pull data from Wikidata using the {WikidataQueryServiceR} package\nVisualize the differences between males and females in the data\n\nI work in healthcare data, so often I cannot share my data or analysis for privacy reasons. This post is my way to share some of the techniques I use at work with data that CAN see the light of day.\nHere I will walk you start to finish, from data pull to pretty plots, to give you some inspiration for your own data analysis projects.\n\n\nData sources\nI originally started working on this analysis and blog post on July 22, 2020, so I have learned a lot of data analytic and programming skills since then, but at the time I had never written a SQL (or one of the many similar SQL-like languages) query outside of an online programming tutorial.\nThis is the command I used to grab the data from the Wikidata Query Service on November 6, 2021 using the {WikidataQueryServiceR} package.\n\n\nCode\nmy_wiki_query <- query_wikidata('SELECT ?item ?dob ?dod ?sex_or_gender WHERE {\n  ?item wdt:P31 wd:Q5;\n  OPTIONAL { ?item wdt:P570 ?dod }\n  OPTIONAL { ?item wdt:P569 ?dob }\n  OPTIONAL { ?item wdt:P21 ?sex_or_gender. }\n}')\n\n\n\n\n\nWith this short command, I was able to quite effortlessly pull data on 3207218 records.\nAs I started out learning R and playing with data, I knew nothing about querying publicly available sources of data. Being able to pull over 3 million rows of data for a toy project is an amazing feat!\nIf you are just starting out in learning R or want to find some great pre-cleaned datasets to work with, check out Tidy Tuesday and follow people’s work on twitter using the #TidyTuesday hashtag.\n\n\n\n\n\nUnderstanding the data\nThe first question I had about the distribution of data on time and by year. I decided to limit myself to the year 1000 onward to be somewhat comparable to the tweets that inspired this post. Here I created a plot to show the distribution of births counts by birth year.\n\n\n\n\n\nSome notable things about the data is the increase of number of available records over time and with an expected drop off as the birth year gets closer to the current year.\nI expected a drop off because it takes most people a certain number of years of life to become notable enough to get a Wikipedia page. While I don’t do this here, I think it would be an interesting analysis to calculate the average age at which a person receives an entry to Wikipedia.\nA fun sub-analysis would to examine differences in the ages by category of notability. For example, I expect that athletes would have a younger age of first entry compared to Nobel Laureates.\nAnother notable trend is that the birth count is high at the start of centuries (eg 1100) compared to intervening years with blunting of that phenomenon from 1500 onward and disappearing around 1800. My instinct is that this reflects the improvement in record keeping and preservation as we approach modern times.\n\n\nSex based differences\nMy prediction prior to exploring the distribution is that women are represented at lower rates in the data compared to men. Graphing the data confirms this. I suppose the surprising insight from the graph is that the proportion of women represented in the data from about 1500 to 1800 is so consistent.\n\n\n\n\n\n\n\n\n\n\nAverage age of death\nI considered two ways to visualize the average of death. The first way is by grouping birth year and seeing the average age of death for that group. As you can see in the graph below, the major issue with that approach is that years close to the present will have very low average ages for death. This happens because in years less than roughly 80 years prior to 2021, anyone who has died, died relatively ‘young’.\n\n\n\n\n\n\n\n\nTo avoid this problem, I instead grouped by death year to show the average age of death for people who died in that year. From these plots we see the average age of death for women flips to be higher than men in the early 20th century and continues until present time.\n\n\n\n\n\n\n\n\nTo compare to tweet 1, I need to exclude deaths that occurred at 20 or under. By examining my plot verses that tweet, it is difficult to compare because I don’t know what smoothing function that the person used to calculate their line. The data before about 1600 has much more variability that data after that point.\n\n\n\n\n\nGiven this, I then investigated what the average age of death looks like from 1600 onward.\n\n\n\n\n\n\n\n\nFinally, let’s look at the data from 1800 onward to investigate the huge expected impacts of both World Wars. While I expected to see the huge impact on age of death in the years 1914 - 1918 and 1939 - 1945, I was surprised to see that the average age of death for both men and women was so affected. I anticipated that men, who are the primary actors in military actions, would have taken a bigger hit than women. While beyond the scope of this post, I think there might be something mysterious going on in the data around the turn of the 21st century with a spike upwards in both sex’s average age of death.\n\n\n\n\n\n\n\n\n\n\nDirty data\nSpeaking of data issues, the final part of my analysis I’d like to share is how many birth dates are represented at higher rates than expected. As mentioned above, before 1800, many people had birth years listed as years like 1000 or 1300. Here I’ll also show how uncertainty of the day of births can be seen in the data.\nThe plot below shows a yellow dot for date that has a 10% or greater number of birth dates than expected under the (somewhat tenuous) assumption that birth days will be distributed equally throughout the year. Notice the nearly straight lines on the y-axis which represents birth dates that fall on the start of a month.\n\n\n\n\n\nDifficult to see on the graph above, but here is a zoomed in version looking only at January birth dates. Here you can see that January 1st is over-represented in the data for literally ever year in the data from 1000 to 2021!\n\n\n\n\n\n\n\nWrap up\nI hope you have enjoyed my mini-journey of exploring the average age of the death over time. It only took me 17 months to finally finish it!\nWhat I hope I can do in future posts is look at data for people beyond those notable enough to have Wikidata entries to see the difference in life expectancies for those more and less notable.\n\n\nTechnical notes\nFor anyone wanting to reproduce my work, you can see my raw code below as well as my R session information. If you repeat the analysis, your data will likely be different than mine as the data pull for this post was done on November 6, 2021.\n\n\nCode\nlibrary(tidyverse)\nlibrary(WikidataQueryServiceR)\nlibrary(lubridate)\nlibrary(stringr)\nlibrary(magrittr)\nlibrary(plotly)\nlibrary(DT)\nlibrary(scales)\nlibrary(ggthemes)\n\nmy_wiki_query <- query_wikidata('SELECT ?item ?dob ?dod ?sex_or_gender WHERE {\n  ?item wdt:P31 wd:Q5;\n  OPTIONAL { ?item wdt:P570 ?dod }\n  OPTIONAL { ?item wdt:P569 ?dob }\n  OPTIONAL { ?item wdt:P21 ?sex_or_gender. }\n}')\n\nmy_wiki_query <- readRDS(\"./data/my_wiki_query.rds\")\n\ncount_query <- nrow(my_wiki_query)\n\n# sex notation\nmy_wiki_query %<>% \n  mutate(simplified_sex = case_when(\n    sex_or_gender == \"http://www.wikidata.org/entity/Q6581072\" ~ 1, #female\n    sex_or_gender == \"http://www.wikidata.org/entity/Q6581097\" ~ 2, #male\n    TRUE ~ 3 #not female, not male\n    ))\n\nmy_wiki_query %<>% \n  dplyr::distinct(item, .keep_all= TRUE) %>% \n  dplyr::mutate(full_year_of_birth = str_extract(dob, \"-?[:digit:]{4}\")) %>% \n  dplyr::mutate(full_year_of_death = str_extract(dod, \"-?[:digit:]{4}\")) %>% \n  dplyr::mutate(approx_age_at_death = as.numeric(full_year_of_death) - as.numeric(full_year_of_birth)) \n\nmy_wiki_query$full_year_of_birth <- as.numeric(my_wiki_query$full_year_of_birth) \nmy_wiki_query$full_year_of_death <- as.numeric(my_wiki_query$full_year_of_death)   \nmy_wiki_query$simplified_sex <- as_factor(my_wiki_query$simplified_sex)\n\nmy_wiki_query %<>% mutate(decade_birth = full_year_of_birth %/% 10)\nmy_wiki_query %>% \n  filter(full_year_of_birth >= 1000 & full_year_of_birth < 2022) %>% \n  filter(simplified_sex == 1 | simplified_sex == 2) %>% \n  ggplot(aes(x = full_year_of_birth)) +\n  geom_histogram(binwidth = 10) +\n  scale_y_log10(breaks=c(100, 1000, 10000, 100000), labels = c(\"100\", \"1000\", \"10,000\", \"100,000\")) +\n  scale_x_continuous(breaks = seq(1000, 2021, 100)) +\n  theme_economist() + \n  labs(title = \"Distribution of births per year\",\n       x = \"Year\",\n       y = \"Birth count per year\",\n       subtitle = \"Years 1000 to 2021\\nLog Scale Y-axis\", \n       caption = \"Including only records with birth years,\\nand restricted to sex of either male or female.\") +\n  coord_cartesian(ylim = c(100, 200000))\nmale_color <- \"#2E45B8\"\nfemale_color <- \"#C91D42\"\n\nsex_proportion_plot <- my_wiki_query %>% \n  filter(simplified_sex == 1 | simplified_sex == 2) %>% \n  filter(full_year_of_birth >= 1000 & full_year_of_birth < 2021) %>% \n#  group_by(decade_birth) %>% \n  ggplot(aes(x = full_year_of_birth, fill = simplified_sex, color = simplified_sex)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(labels = c(\"Female\", \"Male\"), values = c(female_color, male_color)) +\n  scale_color_manual(labels = c(\"Female\", \"Male\"), values = c(female_color, male_color)) +\n  labs(title = \"Proportion of men and women over time in birth cohorts\", \n       x = \"Year of birth\",\n       y = \" \", \n       fill = \"Sex\", \n       color = NULL) +\n  geom_hline(yintercept = 0.5) +\n  theme_economist() +\n  scale_y_continuous(breaks=c(0, 0.25, .5, 0.75, 1), \n                     labels = c(\" \", \" \", \"50%\", \" \", \" \")) +\n  scale_x_continuous(breaks = seq(1000, 2021, 100)) +\n  guides(color = \"none\")\n\nsex_proportion_plot\nce_dates <- my_wiki_query %>% \n  filter(full_year_of_birth >= 1000 & full_year_of_birth <= 2021) %>% \n  filter(full_year_of_death >= 1000 & full_year_of_birth <= 2021) %>% \n  mutate(date_of_birth = as_date(dob)) %>%\n  mutate(year_birth = year(date_of_birth)) %>%\n  mutate(month_birth = month(date_of_birth)) %>%\n  mutate(day_birth = day(date_of_birth)) %>%\n  mutate(date_of_death = as_date(dod)) %>%\n  mutate(year_death = year(date_of_death)) %>%\n  mutate(month_death = month(date_of_death)) %>%\n  mutate(day_death = day(date_of_death)) %>%\n  mutate(lifespan = as.duration(interval(date_of_birth, date_of_death))) %>% \n  filter(lifespan < years(123)) %>% \n  filter(lifespan >= years(0))\naverage_lifespan_by_sex <- ce_dates %>% \n  group_by(year_birth, simplified_sex) %>% \n  summarise(average_age = mean((lifespan)))\n\naverage_lifespan <- ce_dates %>% \n  group_by(year_birth) %>% \n  summarise(average_age = mean((lifespan)))\n\nplot_average_lifespan <- average_lifespan %>%  \n  ggplot(aes(x = year_birth, y = (average_age/31557600))) +\n  geom_smooth(color =   \"#F97A1F\") +\n  geom_point(alpha = 0.05, color =  \"#F97A1F\") +\n  labs(title = \"Average age of death over time\",\n       x = \"Birth Year Cohort\",\n       y = \"Age\") \n\nplot_average_lifespan + theme_economist() + scale_x_continuous(breaks = seq(1000, 2021, 100))\n\naverage_lifespan_by_sex <- ce_dates %>% \n  group_by(year_birth, simplified_sex) %>% \n  summarise(average_age = mean((lifespan)))\n\nplot_average_lifespan_by_sex <- average_lifespan_by_sex %>% \n  filter(simplified_sex != 3) %>% \n  ggplot(aes(x = year_birth, y = (average_age/31557600), color = simplified_sex)) +\n  geom_smooth() +\n  geom_point(alpha = 0.05) +\n  scale_color_manual(labels = c(\"Female\", \"Male\"), values = c(female_color, male_color)) +\n  labs(title = \"Average age of death over time by sex\",\n       x = \"Birth Year Cohort\",\n       y = \"Age\", \n       color = \"Sex\") \n\nplot_average_lifespan_by_sex + theme_economist() + scale_x_continuous(breaks = seq(1000, 2021, 100)) \naverage_lifespan_by_sex_dc <- ce_dates %>% \n  group_by(year_death, simplified_sex) %>% \n  summarise(average_age = mean((lifespan)))\n\naverage_lifespan_dc <- ce_dates %>% \n  group_by(year_death) %>% \n  summarise(average_age = mean((lifespan)))\n\nplot_average_lifespan_dc <- average_lifespan_dc %>%  \n  ggplot(aes(x = year_death, y = (average_age/31557600))) +\n  geom_smooth(color =   \"#F97A1F\") +\n  geom_point(alpha = 0.05, color =  \"#F97A1F\") +\n  labs(title = \"Average age of death over time\",\n       x = \"Death Year Cohort\",\n       y = \"Age\") \n\nplot_average_lifespan_dc  + theme_economist() + scale_x_continuous(breaks = seq(1000, 2021, 100))\n\nplot_average_lifespan_by_sex_dc <- average_lifespan_by_sex_dc %>% \n  filter(simplified_sex != 3) %>% \n  ggplot(aes(x = year_death, y = (average_age/31557600), color = simplified_sex)) +\n  geom_smooth() +\n  geom_point(alpha = 0.05) +\n  scale_color_manual(labels = c(\"Female\", \"Male\"), values = c(female_color, male_color)) +\n  labs(title = \"Average age of death over time by sex\",\n       x = \"Death Year Cohort\",\n       y = \"Age\", \n       color = \"Sex\") \n\nplot_average_lifespan_by_sex_dc + theme_economist() + scale_x_continuous(breaks = seq(1000, 2021, 100))\naverage_lifespan_dc_20 <- ce_dates %>% \n  filter(lifespan > 630720000) %>% \n  group_by(year_death) %>% \n  summarise(average_age = mean((lifespan)))\n\nplot_average_lifespan_dc_20 <- average_lifespan_dc_20  %>%  \n  ggplot(aes(x = year_death, y = (average_age/31557600))) +\n  geom_smooth(color =   \"#F97A1F\") +\n  geom_point(alpha = 0.05, color =  \"#F97A1F\") +\n  labs(title = \"Average age of death over time\",\n       subtitle = \"Only lifespans greater than 20 years\",\n       x = \"Death Year Cohort\",\n       y = \"Age\") \n\nplot_average_lifespan_dc_20 + theme_economist() + scale_x_continuous(breaks = seq(1000, 2021, 100))\nplot_average_lifespan_dc <- average_lifespan_dc %>%  \n  filter(year_death >= 1600) %>% \n  ggplot(aes(x = year_death, y = (average_age/31557600))) +\n  geom_smooth(color =   \"#F97A1F\") +\n  geom_point(alpha = 0.05, color =  \"#F97A1F\") +\n  labs(title = \"Average age of death over time\",\n       x = \"Death Year Cohort\",\n       y = \"Age\") \n\nplot_average_lifespan_dc + \n  theme_economist() + \n  scale_x_continuous(breaks = seq(1000, 2021, 100)) + \n    coord_cartesian(ylim = c(40, 90))\n\nplot_average_lifespan_by_sex_dc <- average_lifespan_by_sex_dc %>% \n  filter(year_death >= 1600) %>% \n  filter(simplified_sex != 3) %>% \n  ggplot(aes(x = year_death, y = (average_age/31557600), color = simplified_sex)) +\n  geom_smooth() +\n  geom_point(alpha = 0.05) +\n  scale_color_manual(labels = c(\"Female\", \"Male\"), values = c(female_color, male_color)) +\n  labs(title = \"Average age of death over time\",\n       x = \"Death Year Cohort\",\n       y = \"Age\", \n       color = \"Sex\") +\n  guides(color = \"none\")\n\nplot_average_lifespan_by_sex_dc + \n  theme_economist() + \n  scale_x_continuous(breaks = seq(1000, 2021, 100)) + \n  coord_cartesian(ylim = c(40, 90))\nyear_cutoff <- 1800\n\nplot_average_lifespan_dc <- average_lifespan_dc %>%  \n  filter(year_death >= year_cutoff) %>% \n  ggplot(aes(x = year_death, y = (average_age/31557600))) +\n  geom_line(color =     \"#F97A1F\") +\n # geom_point(alpha = 0.05, color =     \"#F97A1F\") +\n  labs(title = \"Average age of death over time\",\n       x = \"Death Year Cohort\",\n       y = \"Age\") \n\nplot_average_lifespan_dc + \n  theme_economist() + \n  scale_x_continuous(breaks = seq(1000, 2021, 100)) + \n    coord_cartesian(ylim = c(40, 90))\n\nplot_average_lifespan_by_sex_dc <- average_lifespan_by_sex_dc %>% \n  filter(year_death >= year_cutoff) %>% \n  filter(simplified_sex != 3) %>% \n  ggplot(aes(x = year_death, y = (average_age/31557600), color = simplified_sex)) +\n  geom_line() +\n  scale_color_manual(labels = c(\"Female\", \"Male\"), values = c(female_color, male_color)) +\n  labs(title = \"Average age of death over time by sex\",\n       x = \"Death Year Cohort\",\n       y = \"Age\", \n       color = \"Sex\") +\n  guides(color = \"none\")\n\nplot_average_lifespan_by_sex_dc + \n  theme_economist() + \n  scale_x_continuous(breaks = seq(1000, 2021, 100)) + \n  coord_cartesian(ylim = c(40, 90))\nheatmap_dates <- ce_dates %>% \n  mutate(pad_month_birth = str_pad(month_birth, width = 2, side = \"left\", pad = 0)) %>% \n  mutate(pad_day_birth = str_pad(day_birth, width = 2, side = \"left\", pad = 0)) %>% \n  unite(\"heatdate\", c(year_birth, pad_month_birth, pad_day_birth), sep = \"-\", remove = FALSE) %>% \n  mutate(doy = lubridate::yday(as_date(heatdate)))\n\nheatmap_dates_subset <- heatmap_dates %>% dplyr::select(year_birth, heatdate, doy)\n\nheatmap_data <- heatmap_dates_subset %>% \n  group_by(year_birth, doy) %>% \n  summarise(count = n()) %>% \n  ungroup() %>% \n  group_by(year_birth) %>% \n  mutate(year_total = sum(count)) %>% \n  mutate(proportion_year = count/year_total) %>% \n  mutate(too_high = case_when(\n    proportion_year > 0.003 ~ 1, #roughly 10% higher than expected\n    TRUE ~ 0\n  ))\n\n\ntoo_many_births_plot <- heatmap_data  %>% \n  filter(year_birth >= 1500) %>% \n  ggplot(aes(x = year_birth, y = doy, fill = too_high, text = )) + \n  geom_tile() +\n  scale_fill_gradient(low = \"#475ED1\", high = \"#F9C31F\") + # mid \n  theme_economist() +\n  theme(legend.position = \"none\") +\n  labs(x = \"Year\", \n       y = \" \", \n       title = \"Days of the year with more than expected birthdates\",\n       subtitle = \"Yellow represents with \\\"too\\\" many births \\nY-axis is the day of the year with tick marks to show the start of the month\") +\n  scale_y_continuous(breaks=c(1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335),\n                     labels = c(\"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\", \"O\", \"N\", \"D\"))\n\ntoo_many_births_plot\ntoo_many_births_plot <- heatmap_data  %>% \n  filter(doy < 31) %>% \n  ggplot(aes(x = year_birth, y = doy, fill = too_high, text = )) + \n  geom_tile() +\n  scale_fill_gradient(low = \"#475ED1\", high = \"#F9C31F\") + # mid \n  theme_economist() +\n  theme(legend.position = \"none\") +\n  labs(x = \"Year\", \n       y = \" \", \n       title = \"Days of the year with more than expected birthdates\",\n       subtitle = \"Yellow represents with \\\"too\\\" many births \\nY-axis is the day of the year with tick marks to show the start of the month\") +\n  scale_y_continuous(breaks=c(1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335),\n                     labels = c(\"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\", \"O\", \"N\", \"D\"))\n\ntoo_many_births_plot\n\nsessionInfo()\n\n\n\n\nCode\nsessionInfo()\n\n\nR version 4.2.1 (2022-06-23 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 22621)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] ggthemes_4.2.4              scales_1.2.1               \n [3] DT_0.27                     plotly_4.10.1              \n [5] magrittr_2.0.3              WikidataQueryServiceR_1.0.0\n [7] lubridate_1.9.2             forcats_1.0.0              \n [9] stringr_1.5.0               dplyr_1.1.0                \n[11] purrr_1.0.1                 readr_2.1.4                \n[13] tidyr_1.3.0                 tibble_3.1.8               \n[15] ggplot2_3.4.1               tidyverse_2.0.0            \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.0  xfun_0.37         lattice_0.20-45   splines_4.2.1    \n [5] colorspace_2.1-0  vctrs_0.5.2       generics_0.1.3    htmltools_0.5.4  \n [9] viridisLite_0.4.1 yaml_2.3.7        mgcv_1.8-40       utf8_1.2.3       \n[13] rlang_1.0.6       pillar_1.8.1      glue_1.6.2        withr_2.5.0      \n[17] lifecycle_1.0.3   munsell_0.5.0     gtable_0.3.1      htmlwidgets_1.6.1\n[21] evaluate_0.20     labeling_0.4.2    knitr_1.42        tzdb_0.3.0       \n[25] fastmap_1.1.0     fansi_1.0.4       jsonlite_1.8.4    farver_2.1.1     \n[29] hms_1.1.2         digest_0.6.29     stringi_1.7.8     grid_4.2.1       \n[33] cli_3.6.0         tools_4.2.1       lazyeval_0.2.2    pkgconfig_2.0.3  \n[37] Matrix_1.4-1      ellipsis_0.3.2    data.table_1.14.8 timechange_0.2.0 \n[41] assertthat_0.2.1  rmarkdown_2.20    httr_1.4.5        rstudioapi_0.14  \n[45] ratelimitr_0.4.1  R6_2.5.1          nlme_3.1-157      compiler_4.2.1"
  }
]