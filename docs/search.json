[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Mara‚Äôs Blog",
    "section": "",
    "text": "Holiday Kitchen Tips\n\n\n\nFamily Life\n\n\n\nGet your kitchen and pantry ready for the holiday season\n\n\n\nMara Alexeev\n\n\nNov 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n16th Biggest City per US State\n\n\n\nR\n\n\n\nDown the rabbit hole of US Census Bureau Data\n\n\n\nMara Alexeev\n\n\nJul 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Quest: Energy, Security, and the Remaking of the Modern World\n\n\n\nBook Review\n\n\n\nBrief comments on Yergin‚Äôs work\n\n\n\nMara Alexeev\n\n\nJun 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nChildren: how to expand and contract your world\n\n\n\nFamily Life\n\n\n\nMusings on how my perspectives after children.\n\n\n\nMara Alexeev\n\n\nOct 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nBasics on Birds and Bees!\n\n\n\nMedicine\n\n\n\nThe basics and a bit more on human sex determination\n\n\n\nMara Alexeev\n\n\nSep 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeal plan to end meal planning\n\n\n\nCooking\n\nFamily Life\n\nProject\n\n\n\nHow I learned to stop worrying and love the meal template\n\n\n\nMara Alexeev\n\n\nSep 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaiden, Mother, Matriarch\n\n\n\nFamily Life\n\n\n\nThese Brits and their podcasts\n\n\n\nMara Alexeev\n\n\nAug 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nBook Review: Outlive\n\n\n\nBook Review\n\n\n\nRead Outlive with a physician friend\n\n\n\nMara Alexeev\n\n\nAug 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nFreedom, a critique\n\n\n\nFamily Life\n\nBook Review\n\n\n\nReflections on freedom after motherhood\n\n\n\nMara Alexeev\n\n\nAug 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nDemography is Destiny\n\n\n\nR\n\nProject\n\nBook Review\n\n\n\nWill anyone please think about the children!?\n\n\n\nMara Alexeev\n\n\nJul 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nMom‚Äôs Mood Meter\n\n\n\nR\n\nFamily Life\n\n\n\nPlotting my mood over 5+ years\n\n\n\nMara Alexeev\n\n\nJul 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nUpdates to Shiny App for Creating Blog Posts\n\n\n\nQuarto\n\n\n\nImprove the slug!\n\n\n\nMara Alexeev\n\n\nMar 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nPersonal Website Version 2.0\n\n\n\nQuarto\n\nR\n\nHow-to\n\n\n\nBuilding a new Quarto website\n\n\n\nMara Alexeev\n\n\nMar 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nA sticky bun, but not every day\n\n\n\nR\n\nQuarto\n\nFamily Life\n\n\n\nSolving a cafe mystery\n\n\n\nMara Alexeev\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nCod Liver in Nine Acts\n\n\n\nCooking\n\n\n\nSo much cod liver\n\n\n\nMara Alexeev\n\n\nNov 12, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Prize\n\n\n\nBook Review\n\n\n\nA book report, partially forgotten\n\n\n\nMara Alexeev\n\n\nOct 30, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\nPedestrian Nightmare\n\n\n\nFamily Life\n\n\n\nDreaming about pedestrian first spaces\n\n\n\nMara Alexeev\n\n\nDec 5, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlt Responses to Give the God of Death\n\n\n\nR\n\nProject\n\n\n\nToday???\n\n\n\nMara Alexeev\n\n\nNov 8, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\nRunning My First R Workshop\n\n\n\nR\n\n\n\nAnd thoughts for making it better!\n\n\n\nMara Alexeev\n\n\nMay 25, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrowing Kittens\n\n\n\nR\n\n\n\nHow quickly do kittens gain weight?\n\n\n\nMara Alexeev\n\n\nJan 26, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n2019 R-Medicine Conference Day 1\n\n\n\nR\n\n\n\nShipping up to Boston!\n\n\n\nMara Alexeev\n\n\nSep 12, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals as a chief resident\n\n\n\nMedicine\n\n\n\nGame plan for helping residents at MSKCC Kids\n\n\n\nMara Alexeev\n\n\nSep 2, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe first post of the new website\n\n\n\nHow-to\n\nR\n\nProject\n\n\n\nSquarespace to Blogdown\n\n\n\nMara Alexeev\n\n\nAug 31, 2019\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2025-07-11-16th-biggest-city-per-us-state/index.html",
    "href": "posts/2025-07-11-16th-biggest-city-per-us-state/index.html",
    "title": "16th Biggest City per US State",
    "section": "",
    "text": "Marshalltown, Iowa\nMarshalltown, Iowa is a city in Central Iowa that is probably best known for things you might see in the stores like Lowe‚Äôs and Home Depot: Lennox and the Marshalltown Company. Lennox makes all sorts of AC and heating applicances, and the Marshalltown Company, which makes an incredible number of specialized tools used in everything from tiling your bathroom to archaeological expeditions. I think many of these big ‚Äúhandyman‚Äù stores will have part of an aisle dedicated to these tools. In a story that feels like it could have only ever happened in 19th century America, a single man and local blacksmith, David Lennox, was a pivotal person in both companies.\nI grew up near Marshalltown, and I attended school in Marshalltown until leaving for college in 2004. A friend from medical school messaged me today to tell me that she happened upon the trivia that Marshalltown is the 16th largest city in Iowa. I didn‚Äôt know how to put in that in perspective. I guess that it is probably still under 30,000 people. It seems to be growing slightly when I go visit my parents, and I feel like it was in the 25,000 range when I moved away 21(!) years ago.\n\n\nCensus Bureau\nSo I had to head over to the Census Bureau‚Äôs website to see what the 16th largest cities in other states look like around the United States.\n\n\nCode\nlibrary(tidyverse)\nlibrary(crosstalk)\nlibrary(DT)\n\n\n\n\nCode\n# The path to the local data file\n# The file is in a subfolder called \"data\"\nfile_path &lt;- \"data/sub-est2024.csv\"\n\n# Read the data from the CSV file\n# The 'tryCatch' block will show a helpful message if the file is not found.\nlocal_data &lt;- tryCatch({\n  # Explicitly set the SUMLEV column to be read as character to preserve leading zeros\n  # Added locale to handle \"invalid UTF-8\" warnings by specifying the file encoding.\n  read_csv(file_path, \n           col_types = cols(SUMLEV = col_character()),\n           locale = locale(encoding = \"latin1\"))\n}, error = function(e) {\n  message(\"Error reading file: \", e$message)\n  message(\"\\nPlease make sure '\", file_path, \"' exists and is a valid CSV file.\")\n  # Return an empty tibble or NULL if the file can't be read\n  tibble() \n})\n\n\n\n\nCode\n local_data &lt;- local_data %&gt;%\n    mutate(\n      sumlev_desc = case_when(\n        SUMLEV == \"040\" ~ \"State\",\n        SUMLEV == \"050\" ~ \"County\",\n        SUMLEV == \"061\" ~ \"Minor Civil Division\",\n        SUMLEV == \"071\" ~ \"Minor Civil Division place part\",\n        SUMLEV == \"157\" ~ \"County place part\",\n        SUMLEV == \"162\" ~ \"Incorporated place\",\n        SUMLEV == \"170\" ~ \"Consolidated city\",\n        SUMLEV == \"172\" ~ \"Consolidated city -- place within consolidated city\",\n        TRUE ~ \"Other\" # A default for any values not in the key\n      )\n    )\n\n\nBut before we get to granular level data, let‚Äôs just look at the state level. Who is #16???\n\n\nCode\n  ranked_states &lt;- local_data %&gt;%\n    filter(SUMLEV == \"040\") %&gt;%\n    arrange(desc(ESTIMATESBASE2020)) %&gt;%\n    mutate(Rank = row_number()) %&gt;%\n    select(Rank, STNAME, ESTIMATESBASE2020)\n\n  # Assign the 16th ranked state name to a variable\n  state_16 &lt;- ranked_states$STNAME[16]\n\n  # Display the table\n  knitr::kable(\n    ranked_states,\n    caption = \"State Population for 2020 Census, in Descending Order\",\n    col.names = c(\"Rank\", \"State Name\", \"2020 Population Base\"),\n    format.args = list(big.mark = \",\"))\n\n\n\nState Population for 2020 Census, in Descending Order\n\n\nRank\nState Name\n2020 Population Base\n\n\n\n\n1\nCalifornia\n39,555,674\n\n\n2\nTexas\n29,149,458\n\n\n3\nFlorida\n21,538,192\n\n\n4\nNew York\n20,203,772\n\n\n5\nPennsylvania\n13,002,909\n\n\n6\nIllinois\n12,821,814\n\n\n7\nOhio\n11,799,453\n\n\n8\nGeorgia\n10,713,755\n\n\n9\nNorth Carolina\n10,441,499\n\n\n10\nMichigan\n10,079,338\n\n\n11\nNew Jersey\n9,289,014\n\n\n12\nVirginia\n8,631,388\n\n\n13\nWashington\n7,707,586\n\n\n14\nArizona\n7,158,110\n\n\n15\nMassachusetts\n7,033,132\n\n\n16\nTennessee\n6,912,347\n\n\n17\nIndiana\n6,786,587\n\n\n18\nMaryland\n6,181,629\n\n\n19\nMissouri\n6,154,854\n\n\n20\nWisconsin\n5,894,170\n\n\n21\nColorado\n5,775,324\n\n\n22\nMinnesota\n5,706,692\n\n\n23\nSouth Carolina\n5,118,252\n\n\n24\nAlabama\n5,025,369\n\n\n25\nLouisiana\n4,657,874\n\n\n26\nKentucky\n4,506,302\n\n\n27\nOregon\n4,237,224\n\n\n28\nOklahoma\n3,959,405\n\n\n29\nConnecticut\n3,607,701\n\n\n30\nUtah\n3,271,608\n\n\n31\nIowa\n3,190,546\n\n\n32\nNevada\n3,105,595\n\n\n33\nArkansas\n3,011,553\n\n\n34\nMississippi\n2,961,278\n\n\n35\nKansas\n2,937,745\n\n\n36\nNew Mexico\n2,117,555\n\n\n37\nNebraska\n1,961,996\n\n\n38\nIdaho\n1,839,140\n\n\n39\nWest Virginia\n1,793,736\n\n\n40\nHawaii\n1,455,252\n\n\n41\nNew Hampshire\n1,377,546\n\n\n42\nMaine\n1,363,196\n\n\n43\nRhode Island\n1,097,354\n\n\n44\nMontana\n1,084,216\n\n\n45\nDelaware\n989,955\n\n\n46\nSouth Dakota\n886,729\n\n\n47\nNorth Dakota\n779,046\n\n\n48\nAlaska\n733,395\n\n\n49\nDistrict of Columbia\n689,545\n\n\n50\nVermont\n643,082\n\n\n51\nWyoming\n576,844\n\n\n\n\n\nSo our 16th largest state is Tennessee!\nBut let‚Äôs see what the 16th largest ‚Äúcity‚Äù is in each state. I will need to get some better understanding of how the Census Bureau defines their cities to make sure I am filtering on the correct codes, but I want to get this out quickly for my curious friends! Marshalltown does come out as the 16th based on 2020 population estimates.\n\n\nCode\n  ranked_cities_by_state_all &lt;- local_data %&gt;%\n    distinct(STNAME, NAME, ESTIMATESBASE2020, .keep_all = TRUE) %&gt;%\n    filter(SUMLEV %in% c( \"162\", \"61\", \"50\")) %&gt;%\n    group_by(STNAME) %&gt;%\n    arrange(desc(ESTIMATESBASE2020)) %&gt;%\n    mutate(Rank = row_number()) %&gt;%\n    filter(Rank == 16 ) %&gt;%\n    ungroup() %&gt;%\n    select(STNAME, NAME, ESTIMATESBASE2020) %&gt;%\n    arrange(STNAME)\n\n    ranked_cities_by_state_all %&gt;%\n      mutate(Order = row_number()) %&gt;%\n  relocate(Order) %&gt;%\n      \n    knitr::kable(\n    caption = \"16th Largest City or Place by 2020 Population Within Each State order alphabetically by State Name\",\n    col.names = c(\"Order\", \"State Name\", \"Place Name\", \"2020 Census Population\"),\n    format.args = list(big.mark = \",\")\n  )\n\n\n\n16th Largest City or Place by 2020 Population Within Each State order alphabetically by State Name\n\n\nOrder\nState Name\nPlace Name\n2020 Census Population\n\n\n\n\n1\nAlabama\nAlabaster city\n33,342\n\n\n2\nAlaska\nNome city\n3,695\n\n\n3\nArizona\nQueen Creek town\n59,489\n\n\n4\nArkansas\nJacksonville city\n29,483\n\n\n5\nCalifornia\nSanta Clarita city\n232,809\n\n\n6\nColorado\nCastle Rock town\n73,158\n\n\n7\nConnecticut\nTorrington city\n35,503\n\n\n8\nDelaware\nMilton town\n3,315\n\n\n9\nFlorida\nPalm Bay city\n119,751\n\n\n10\nGeorgia\nStonecrest city\n59,189\n\n\n11\nIdaho\nMountain Home city\n16,064\n\n\n12\nIllinois\nBolingbrook village\n73,949\n\n\n13\nIndiana\nAnderson city\n54,848\n\n\n14\nIowa\nMarshalltown city\n27,592\n\n\n15\nKansas\nDerby city\n25,660\n\n\n16\nKentucky\nPaducah city\n27,130\n\n\n17\nLouisiana\nHammond city\n19,632\n\n\n18\nMaine\nOld Town city\n7,438\n\n\n19\nMaryland\nEaston town\n17,103\n\n\n20\nMassachusetts\nMalden city\n66,274\n\n\n21\nMichigan\nKalamazoo city\n73,547\n\n\n22\nMinnesota\nCoon Rapids city\n63,636\n\n\n23\nMississippi\nBrandon city\n25,097\n\n\n24\nMissouri\nJefferson City city\n43,237\n\n\n25\nMontana\nLewistown city\n5,955\n\n\n26\nNebraska\nLexington city\n10,663\n\n\n27\nNevada\nCarlin city\n2,051\n\n\n28\nNew Jersey\nPlainfield city\n54,600\n\n\n29\nNew Mexico\nArtesia city\n12,875\n\n\n30\nNew York\nFreeport village\n44,472\n\n\n31\nNorth Carolina\nChapel Hill town\n62,264\n\n\n32\nNorth Dakota\nHorace city\n3,206\n\n\n33\nOhio\nMiddletown city\n50,986\n\n\n34\nOklahoma\nJenks city\n25,946\n\n\n35\nOregon\nOregon City city\n37,585\n\n\n36\nPennsylvania\nChester city\n32,724\n\n\n37\nSouth Carolina\nAnderson city\n29,441\n\n\n38\nSouth Dakota\nMadison city\n6,193\n\n\n39\nTennessee\nCleveland city\n47,799\n\n\n40\nTexas\nGrand Prairie city\n196,075\n\n\n41\nUtah\nDraper city\n51,025\n\n\n42\nVermont\nEnosburg Falls village\n1,351\n\n\n43\nVirginia\nManassas city\n42,773\n\n\n44\nWashington\nPasco city\n77,345\n\n\n45\nWest Virginia\nOak Hill city\n8,167\n\n\n46\nWisconsin\nBrookfield city\n41,465\n\n\n47\nWyoming\nTorrington city\n6,128\n\n\n\n\n\nCode\n    ranked_cities_by_state_by_pop &lt;-ranked_cities_by_state_all %&gt;% \n      arrange(desc(ESTIMATESBASE2020)) %&gt;% mutate(Order = row_number()) %&gt;%\n  relocate(Order) \n    \n\n    knitr::kable(ranked_cities_by_state_by_pop ,\n    caption = \"16th Largest City or Place by 2020 Census Population Within Each State ordered by Population Size\",\n    col.names = c(\"Order\", \"State Name\", \"Place Name\", \"2020 Census Population\"),\n    format.args = list(big.mark = \",\")\n  )\n\n\n\n16th Largest City or Place by 2020 Census Population Within Each State ordered by Population Size\n\n\nOrder\nState Name\nPlace Name\n2020 Census Population\n\n\n\n\n1\nCalifornia\nSanta Clarita city\n232,809\n\n\n2\nTexas\nGrand Prairie city\n196,075\n\n\n3\nFlorida\nPalm Bay city\n119,751\n\n\n4\nWashington\nPasco city\n77,345\n\n\n5\nIllinois\nBolingbrook village\n73,949\n\n\n6\nMichigan\nKalamazoo city\n73,547\n\n\n7\nColorado\nCastle Rock town\n73,158\n\n\n8\nMassachusetts\nMalden city\n66,274\n\n\n9\nMinnesota\nCoon Rapids city\n63,636\n\n\n10\nNorth Carolina\nChapel Hill town\n62,264\n\n\n11\nArizona\nQueen Creek town\n59,489\n\n\n12\nGeorgia\nStonecrest city\n59,189\n\n\n13\nIndiana\nAnderson city\n54,848\n\n\n14\nNew Jersey\nPlainfield city\n54,600\n\n\n15\nUtah\nDraper city\n51,025\n\n\n16\nOhio\nMiddletown city\n50,986\n\n\n17\nTennessee\nCleveland city\n47,799\n\n\n18\nNew York\nFreeport village\n44,472\n\n\n19\nMissouri\nJefferson City city\n43,237\n\n\n20\nVirginia\nManassas city\n42,773\n\n\n21\nWisconsin\nBrookfield city\n41,465\n\n\n22\nOregon\nOregon City city\n37,585\n\n\n23\nConnecticut\nTorrington city\n35,503\n\n\n24\nAlabama\nAlabaster city\n33,342\n\n\n25\nPennsylvania\nChester city\n32,724\n\n\n26\nArkansas\nJacksonville city\n29,483\n\n\n27\nSouth Carolina\nAnderson city\n29,441\n\n\n28\nIowa\nMarshalltown city\n27,592\n\n\n29\nKentucky\nPaducah city\n27,130\n\n\n30\nOklahoma\nJenks city\n25,946\n\n\n31\nKansas\nDerby city\n25,660\n\n\n32\nMississippi\nBrandon city\n25,097\n\n\n33\nLouisiana\nHammond city\n19,632\n\n\n34\nMaryland\nEaston town\n17,103\n\n\n35\nIdaho\nMountain Home city\n16,064\n\n\n36\nNew Mexico\nArtesia city\n12,875\n\n\n37\nNebraska\nLexington city\n10,663\n\n\n38\nWest Virginia\nOak Hill city\n8,167\n\n\n39\nMaine\nOld Town city\n7,438\n\n\n40\nSouth Dakota\nMadison city\n6,193\n\n\n41\nWyoming\nTorrington city\n6,128\n\n\n42\nMontana\nLewistown city\n5,955\n\n\n43\nAlaska\nNome city\n3,695\n\n\n44\nDelaware\nMilton town\n3,315\n\n\n45\nNorth Dakota\nHorace city\n3,206\n\n\n46\nNevada\nCarlin city\n2,051\n\n\n47\nVermont\nEnosburg Falls village\n1,351\n\n\n\n\n\nLet‚Äôs see what happened over the past 5 years in Iowa with the top 25 cities. Did Marshalltown hold on in 2024???\n\n\nCode\n  ranked_cities_by_iowa &lt;- local_data %&gt;%\n  filter(STNAME == \"Iowa\") %&gt;%\nfilter(SUMLEV %in% c( \"162\", \"61\", \"50\")) %&gt;%\n    arrange(desc(POPESTIMATE2024)) %&gt;%\n    mutate(Rank = row_number()) %&gt;%\n    filter(Rank &lt;= 25 ) %&gt;%\n   \n    select(\n      NAME,\n      Rank,\n      ESTIMATESBASE2020,\n    \n      POPESTIMATE2021,\n      POPESTIMATE2022,\n      POPESTIMATE2023,\n      POPESTIMATE2024\n    ) %&gt;%\n  arrange(Rank) %&gt;%\n  \n    knitr::kable(\n      caption = \"Population Data for Iowa\",\n       col.names = c(\"Place Name\", \"Rank\", \"2020 Pop. Est.\", \"2021 Pop. Est.\", \"2022 Pop. Est.\", \"2023 Pop. Est.\", \"2024 Pop. Est.\"),\n      format.args = list(big.mark = \",\")\n    )\n\n ranked_cities_by_iowa\n\n\n\nPopulation Data for Iowa\n\n\n\n\n\n\n\n\n\n\n\nPlace Name\nRank\n2020 Pop. Est.\n2021 Pop. Est.\n2022 Pop. Est.\n2023 Pop. Est.\n2024 Pop. Est.\n\n\n\n\nDes Moines city\n1\n214,058\n212,539\n210,950\n211,088\n213,096\n\n\nCedar Rapids city\n2\n137,732\n137,112\n136,861\n136,637\n137,904\n\n\nDavenport city\n3\n101,730\n101,052\n100,469\n100,509\n100,938\n\n\nSioux City city\n4\n85,894\n85,904\n85,568\n86,284\n86,875\n\n\nAnkeny city\n5\n68,095\n70,635\n72,416\n74,822\n76,727\n\n\nIowa City city\n6\n74,825\n75,180\n75,867\n76,111\n76,710\n\n\nWest Des Moines city\n7\n68,725\n69,913\n70,751\n72,518\n73,664\n\n\nAmes city\n8\n66,432\n67,028\n67,329\n68,428\n69,026\n\n\nWaterloo city\n9\n67,309\n66,895\n66,530\n66,856\n67,477\n\n\nCouncil Bluffs city\n10\n62,781\n62,582\n62,405\n62,535\n62,665\n\n\nDubuque city\n11\n59,676\n59,281\n58,928\n58,941\n58,987\n\n\nUrbandale city\n12\n45,577\n45,998\n46,650\n46,931\n47,759\n\n\nMarion city\n13\n41,552\n41,660\n41,607\n42,127\n42,542\n\n\nCedar Falls city\n14\n40,728\n40,672\n40,584\n41,095\n41,417\n\n\nBettendorf city\n15\n39,101\n39,333\n39,584\n39,941\n40,281\n\n\nWaukee city\n16\n23,949\n26,487\n29,154\n31,750\n34,420\n\n\nMarshalltown city\n17\n27,592\n27,461\n27,491\n27,737\n27,886\n\n\nMason City city\n18\n27,351\n27,180\n26,909\n26,954\n26,948\n\n\nOttumwa city\n19\n25,545\n25,408\n25,217\n25,438\n25,648\n\n\nJohnston city\n20\n23,937\n24,092\n24,225\n24,598\n25,022\n\n\nFort Dodge city\n21\n24,871\n25,036\n24,705\n24,702\n24,886\n\n\nClinton city\n22\n24,467\n24,463\n24,356\n24,230\n24,118\n\n\nCoralville city\n23\n22,333\n22,939\n23,191\n23,723\n23,959\n\n\nBurlington city\n24\n24,022\n23,769\n23,606\n23,659\n23,637\n\n\nMuscatine city\n25\n23,809\n23,496\n23,499\n23,400\n23,298\n\n\n\n\n\nWaukeeeeeeee!! üòà\n\n\nLooking for the outliers\nWhile I don‚Äôt think I understand my data well enough!\n\n\nCode\nlocal_data %&gt;%\n    filter(SUMLEV %in% c(\"162\", \"61\", \"50\")) %&gt;%\n    group_by(STNAME) %&gt;%\n    summarise(Count = n(), .groups = 'drop') %&gt;% \n    arrange(Count) %&gt;%\n    knitr::kable(\n      caption = \"Count of Selected Places per State\", \n      col.names = c(\"State Name\", \"Selected Places\")\n    )\n\n\n\nCount of Selected Places per State\n\n\nState Name\nSelected Places\n\n\n\n\nDistrict of Columbia\n1\n\n\nHawaii\n1\n\n\nRhode Island\n8\n\n\nNew Hampshire\n13\n\n\nNevada\n19\n\n\nMaine\n23\n\n\nConnecticut\n30\n\n\nVermont\n39\n\n\nDelaware\n57\n\n\nMassachusetts\n58\n\n\nArizona\n91\n\n\nWyoming\n99\n\n\nNew Mexico\n105\n\n\nMontana\n127\n\n\nAlaska\n149\n\n\nMaryland\n157\n\n\nIdaho\n198\n\n\nVirginia\n227\n\n\nWest Virginia\n230\n\n\nOregon\n240\n\n\nUtah\n255\n\n\nColorado\n271\n\n\nSouth Carolina\n271\n\n\nWashington\n281\n\n\nMississippi\n299\n\n\nLouisiana\n304\n\n\nSouth Dakota\n310\n\n\nNew Jersey\n323\n\n\nTennessee\n345\n\n\nNorth Dakota\n355\n\n\nFlorida\n411\n\n\nKentucky\n418\n\n\nAlabama\n463\n\n\nCalifornia\n482\n\n\nArkansas\n500\n\n\nNebraska\n528\n\n\nMichigan\n533\n\n\nGeorgia\n537\n\n\nNorth Carolina\n549\n\n\nIndiana\n566\n\n\nOklahoma\n591\n\n\nNew York\n595\n\n\nWisconsin\n607\n\n\nKansas\n626\n\n\nMinnesota\n855\n\n\nOhio\n923\n\n\nMissouri\n938\n\n\nIowa\n940\n\n\nPennsylvania\n1013\n\n\nTexas\n1224\n\n\nIllinois\n1294\n\n\n\n\n\nCheck out Hawaii, New Hampshire, and Rhode Island below. My filtering above is not capturing what I believe reality is, or rather what typical non-Census Bureau people think about what should be on that list. I suspect I am filtering a variable called SUMLEV incorrectly or incorrectly for some states, which might have special ways they show up in the data.\n\n\n\n\n\n\nSelect a State:"
  },
  {
    "objectID": "posts/2024-09-20-growing-kittens/index.html",
    "href": "posts/2024-09-20-growing-kittens/index.html",
    "title": "Growing Kittens",
    "section": "",
    "text": "Reason, Rebel, Rhyme after their first bath."
  },
  {
    "objectID": "posts/2024-09-20-growing-kittens/index.html#import-and-tidy-data",
    "href": "posts/2024-09-20-growing-kittens/index.html#import-and-tidy-data",
    "title": "Growing Kittens",
    "section": "Import and tidy data",
    "text": "Import and tidy data\nThe libraries I have loaded are tidyverse, janitor, googlesheets4 (this was added to the updated blog post and code in 2024), and tools. I tried to figure out if their was a code chuck option to show the code, but not show the evaluation of it, but didn‚Äôt find it. I‚Äôll need to search through R Markdown. Update found it. Looks like I need to set message to false.\n\n\nCode\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(googlesheets4)\nlibrary(tools)\n\n\n\n\nCode\n#Read google sheets data into R\nkitten_weight_gain &lt;- read_sheet('https://docs.google.com/spreadsheets/d/1x-Udhm5VkhSh0siWLtipbDZFAMs5Zp7TsTpnUlmz9Jg/edit?gid=0#gid=0')\n                                                                                        \n\n#names(kitten_weight_gain)\n\n\n\n\nCode\nkitten_weight_gain &lt;- clean_names(kitten_weight_gain)\n\ntidy_kittens &lt;- pivot_longer(kitten_weight_gain, cols = 3:5, names_to = \"kitten_name\", values_to = \"weight_in_grams\") \n\ntidy_kittens &lt;- tidy_kittens %&gt;% separate(col = 4, into = c(\"kitten_name\", \"sex\"), sep = \"_\")\n\ntidy_kittens$sex &lt;- as.factor(tidy_kittens$sex)\n\ntidy_kittens$scale &lt;- as.factor(tidy_kittens$scale)\n\ntidy_kittens$date &lt;- as.Date(tidy_kittens$date, format = \"%m/%d/%Y\")\n\ntidy_kittens$weight_in_grams &lt;- as.numeric(tidy_kittens$weight_in_grams)\n\ntidy_kittens$kitten_name &lt;- tools::toTitleCase(tidy_kittens$kitten_name)\n\n#head(tidy_kittens)\n\n\nOk now I have my data in a more tidy format. This is the first time I have used dpylr::pivot_longer. I first tried to use dpylr::spread but saw a little note that pivot_longer was the new kid in town. I thought it was great. Certainly was faster for me to use even though it was the first time reading through the documentation."
  },
  {
    "objectID": "posts/2024-09-20-growing-kittens/index.html#weight-gain-graphically",
    "href": "posts/2024-09-20-growing-kittens/index.html#weight-gain-graphically",
    "title": "Growing Kittens",
    "section": "Weight gain, graphically",
    "text": "Weight gain, graphically\nI want to denote a few things in my graph: distinguish the two males from the female kitten, note that the first day‚Äôs wieght was by a different scale. And I‚Äôd love to somehow squeeze a picture of the kitten into its key‚Äìbut since I only have a few minutes before my toddler wakes up‚Äìbasics first.\n\n\nCode\ngraphic_kittens &lt;- ggplot(tidy_kittens, aes(x = date, y = weight_in_grams, color = kitten_name, shape = sex)) +\n  geom_line() +\n  geom_point() +\n  labs(title = \"Foster Kitten Weight Gain\", subtitle = \"Journey to adequate weight for neutering and adoption\") +\n  xlab(\" \") +\n  ylab(\"Weight in grams\") +\n  theme_minimal() +\n  scale_x_date(date_breaks = \"1 day\", date_labels = \"%b-%d\")+\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  labs(color = \"Which kitten?\") +\n  labs(shape = \"Sex of kitten?\") \n  \n\n\nprint(graphic_kittens)"
  },
  {
    "objectID": "posts/2024-09-20-growing-kittens/index.html#next-steps",
    "href": "posts/2024-09-20-growing-kittens/index.html#next-steps",
    "title": "Growing Kittens",
    "section": "Next steps",
    "text": "Next steps\nQuestions I have now after the first collection of data:\nDo males and females have different weight gain rates?\nDo any animal shelters moniter weight gain as an indicator of kitten well being like we have for infant/child growth curves as humans?\nWhat are the currently known determinants of weight gain in domestic kittens? Though these kittens were supposedly siblings, queens can have a single litter with multiple toms fathering kittens, so the kittens from a single litter might be more or less related."
  },
  {
    "objectID": "posts/2023-07-22-mom-s-mood-meter/index.html",
    "href": "posts/2023-07-22-mom-s-mood-meter/index.html",
    "title": "Mom‚Äôs Mood Meter",
    "section": "",
    "text": "Tracking happiness, stress, and tiredness\nIn May 2018, I started tracking on a daily basis four variables once per day: discomfort, happiness, stress, and tiredness. I typically do the rating before bed as I journal.\nI rate my status on these variables on a minus two to plus two scale. All variables have the same direction of ‚Äògoodness‚Äô. For example, plus two on the tiredness scale means I feel completely rested and have more than enough energy to do everything I wanted in a day, whereas minus two means I feel like I don‚Äôt have enough energy to do the minimum amount of things needed to scrap by in a day. Plus two on the discomfort scale means my body feels amazing and I have no discomfort.\nI have plotted the 28 day rolling mean of the value ratings below.\nAs I write this blog, I am fairly shocked by a few parts of the plot. First, I do not remember feeling so happy or rested as the plot seems to indicate after the birth of my first child (June 2018). Also it seems a two week break in July 2022 from work outside the home had huge effect on all four variables for a fair amount of time afterwards. I plan to investigate what happened in Spring 2019 that was temporally related to a significant downward shift of all ratings. Without referring back to my journal, I recall that Spring being highly influenced by trying to re-enter the workforce.\nSome notable events are denoted with vertical lines on the plot:\n\nJune 2018: birth of first child\nSept 2019: return to work\nMarch 2020: living apart from husband and son during pandemic for approximately 100 days\nJuly 2020: start of fellowship\nAugust 2020: birth of second child\nJuly 2022: start of new job\n\nI think the most exciting part of finally seeing this data is now planning to try a few different interventions on myself for 4 week periods to see if I can see meaningful changes to my rolling mean in any of the four areas.\nAn aspect not well captured in these plots is my sense of meaning. I have a tremendous sense of meaning in my life since having children. While that might seem like an improvement, I want even more! The kicks just keep getting harder to get, and now I crave more meaning in my life: more engagement with friends, family, my local community. It‚Äôs as if my children unlocked a new level of connection to the world and expanded my capacity to care about things I hadn‚Äôt even noticed in my life before.\n\n\n\n\n\n\n\n\n\n\n\nCombining it all\nI think the combination of discomfort, happiness, stress, and tiredness are some of the biggest indicators of what my overall mood would probably be. When I look at the four measures summed up, I see following trends. I remain impressed that the year after my first child was born, I was rating myself so highly in all four areas."
  },
  {
    "objectID": "posts/2023-03-05-personal-website-version-2/index.html",
    "href": "posts/2023-03-05-personal-website-version-2/index.html",
    "title": "Personal Website Version 2.0",
    "section": "",
    "text": "I wanted to move away from my ‚Äúoriginal‚Äù blogdown method of blogging because I am really enthused about how great Quarto is. My blogdown project had accumulated so much code debris over the years because I started it when I was first learning to code, that it seemed easier to just take the posts and migrate them to a new Quarto Website + Blog than correcting all the mistakes accumulated over 4 years. I am initially going to post this on Github Pages, but once I have migrated content from my old site, I will reassign this repo to my Netlify account to deploy to my personalized domain.\nThree things I wanted out of the new website:\n\nMake writing posts easy. Quarto does not have an add-in (yet) like Blogdown does to create a new blog post. So I leaned very, very heavily on Mark Edney‚Äôs R-Blogger‚Äôs post on how to make a handy Shiny app to take the thinking out of setting up each blog post. The rough part of being just excited enough to blog, but with huge time constraints is that I might go months in between posting and inevitably forget things and it frustrates me.\nHave a website plus a blog so the Quarto Website + Blog was a great combo idea that I was able to execute with help from a post by Samantha Csik.\nEnable discussions on my blog. I don‚Äôt think I have much traffic on my blog, but I know a few people have used things I have written because when I was Googling myself I found someone thanking me in their blog post about something I had had to troubleshoot in my blog and of course then blogged about it. Last fall I saw a cool method called giscus, so will use that.\n\n\n\nFor setting up the Shiny App, the only major change I did was to make a multi-select option for categories for my blog post template from Mark‚Äôs original work. This is nice because it helps me make sure I am not duplicating categories (eg Medicine and medicine) because categories are case sensitive. I also added a data-modified section to my template because I like to capture when I update a post. Also, I love the YAML template including draft = 'true' to harder to accidentally post a draft version of your post.\nHere‚Äôs the whole app below.\n\n\nCode\n# Source https://www.r-bloggers.com/2022/08/creating-posts-for-quarto-blog/\n#\n\nlibrary(shiny)\nlibrary(miniUI)\n\nQGadget &lt;- function() {....}\n\nui &lt;- miniUI::miniPage(\n  miniUI::gadgetTitleBar(\"Quarto Blog Post\"),\n  miniUI::miniContentPanel(\n    shiny::textInput(\"title\", \"Title\", placeholder = \"Post Title\"),\n    shiny::selectInput(\"categories\", \"Categories\", \n                       choices = list(\"How-to\", \n                                      \"R\", \"Python\", \"Quarto\",\n                                      \"Medicine\", \n                                      \"Family Life\", \"Cooking\"),\n                       multiple = TRUE)\n\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  \n  shiny::observeEvent(input$done, {\n    Blog_post(input$title, input$categories)\n    stopApp(\"Post Created\")\n  })\n}\n\nshiny::runGadget(ui, server, viewer = shiny::dialogViewer(\"Quarto Blog Post\"))\n\nBlog_post &lt;- function(title, categories){\n  data &lt;- list(title = title,\n               author = \"'Mara Alexeev'\",\n               date = Sys.Date(),\n               date_modified = \"'`r Sys.Date()`'\",\n               categories = categories,\n                 \n               draft = 'true',\n               description = \"''\",\n               image = \"''\",\n               archives = format(date, \"%Y/%m\"),\n               toc = 'false',\n               fold = \"true\",\n               tools = 'true',\n               link =  'false')\n  \n  Template &lt;- '---\ntitle: {{title}}\nauthor: {{author}}\ndate: {{date}}\ndate-modified: {{date_modified}}\ncategories: [{{categories}}]\ndraft: {{draft}}\ndescription: {{description}}\nimage: {{image}}\narchives:\n  - {{archives}}\ntoc: {{toc}}\n\nformat:\n  html:\n    code-fold: {{fold}}\n    code-tools: {{tools}}\n---\n\n# Introduction\n\n# Conclusion\n\n'\n  \n  dir.create(paste0(\"./posts/\",data$date, \"-\", title))\n  writeLines(whisker::whisker.render(Template, data), paste0(\"./posts/\",data$date, \"-\", title, \"/index.qmd\"))\n  file.edit(paste0(\"./posts/\",data$date, \"-\", title, \"/index.qmd\"))\n}\n\n\n\n\n\nSamantha points out that a Quarto Blog is just a special point of a Quarto website. I actually got a little concerned about using Quarto as my blog because the directions of how to set up the individual posts had a lot of steps that I was worried I would not be able to do consistently over time. That‚Äôs when I thought to write a script to do it for me, and instead was saved several hours of work by Mark‚Äôs post.\n\n\n\nOkay, so this is the main thrust of this post: Giscus. Which has painfully cute name. I was actually able to set it up on a test Quarto Book project, but of course that was months ago, and I can‚Äôt remember the process because I didn‚Äôt write it down! So for myself and for everyone else, here I go!\nFirst, why did I choose giscus? I loved that it supported multiple languages (human languages because I sometimes blog about languages that don‚Äôt use the Latin alphabet), it has some math notation ability, and it is open source and has a great github page.\n\n\n\n\nYou have to add giscus as an app on Github.\nDepending on your settings, you additionally may need to add the repo of interest to you configuration settings on giscus.\nEnable discussions on your repo (settings -&gt; features -&gt; discussions).\nGo to giscus.app and follow instructions there and it will give you some good information like repo-id which you will need to put in your _quarto.yml.\nTake the information from the giscus.app and update your _quarto.yml to include information about the repo, giscus, and some ids. Unfortunately, it is not formatted the way you need to put it into the _quarto.yml.\n\n  comments: \n    giscus:\n      repo: MaraAlexeev/personal_website_v2\n      repo-id: FAKE_REPO_ID #Get this from giscus.app\n      category: General\n      category-id: FAKE_CATEGORY_ID #Get this from giscus.app\n      mapping: title #pathname was very gross format\n      reactions-enabled: TRUE\n      input-position: bottom\n      theme: light\n\nFor pages you don‚Äôt want to have comments on put in the yaml header of that page comments: false. I do this for my blog post listing page and my about page."
  },
  {
    "objectID": "posts/2023-03-05-personal-website-version-2/index.html#shiny-app-for-blog-post-creation",
    "href": "posts/2023-03-05-personal-website-version-2/index.html#shiny-app-for-blog-post-creation",
    "title": "Personal Website Version 2.0",
    "section": "",
    "text": "For setting up the Shiny App, the only major change I did was to make a multi-select option for categories for my blog post template from Mark‚Äôs original work. This is nice because it helps me make sure I am not duplicating categories (eg Medicine and medicine) because categories are case sensitive. I also added a data-modified section to my template because I like to capture when I update a post. Also, I love the YAML template including draft = 'true' to harder to accidentally post a draft version of your post.\nHere‚Äôs the whole app below.\n\n\nCode\n# Source https://www.r-bloggers.com/2022/08/creating-posts-for-quarto-blog/\n#\n\nlibrary(shiny)\nlibrary(miniUI)\n\nQGadget &lt;- function() {....}\n\nui &lt;- miniUI::miniPage(\n  miniUI::gadgetTitleBar(\"Quarto Blog Post\"),\n  miniUI::miniContentPanel(\n    shiny::textInput(\"title\", \"Title\", placeholder = \"Post Title\"),\n    shiny::selectInput(\"categories\", \"Categories\", \n                       choices = list(\"How-to\", \n                                      \"R\", \"Python\", \"Quarto\",\n                                      \"Medicine\", \n                                      \"Family Life\", \"Cooking\"),\n                       multiple = TRUE)\n\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  \n  shiny::observeEvent(input$done, {\n    Blog_post(input$title, input$categories)\n    stopApp(\"Post Created\")\n  })\n}\n\nshiny::runGadget(ui, server, viewer = shiny::dialogViewer(\"Quarto Blog Post\"))\n\nBlog_post &lt;- function(title, categories){\n  data &lt;- list(title = title,\n               author = \"'Mara Alexeev'\",\n               date = Sys.Date(),\n               date_modified = \"'`r Sys.Date()`'\",\n               categories = categories,\n                 \n               draft = 'true',\n               description = \"''\",\n               image = \"''\",\n               archives = format(date, \"%Y/%m\"),\n               toc = 'false',\n               fold = \"true\",\n               tools = 'true',\n               link =  'false')\n  \n  Template &lt;- '---\ntitle: {{title}}\nauthor: {{author}}\ndate: {{date}}\ndate-modified: {{date_modified}}\ncategories: [{{categories}}]\ndraft: {{draft}}\ndescription: {{description}}\nimage: {{image}}\narchives:\n  - {{archives}}\ntoc: {{toc}}\n\nformat:\n  html:\n    code-fold: {{fold}}\n    code-tools: {{tools}}\n---\n\n# Introduction\n\n# Conclusion\n\n'\n  \n  dir.create(paste0(\"./posts/\",data$date, \"-\", title))\n  writeLines(whisker::whisker.render(Template, data), paste0(\"./posts/\",data$date, \"-\", title, \"/index.qmd\"))\n  file.edit(paste0(\"./posts/\",data$date, \"-\", title, \"/index.qmd\"))\n}"
  },
  {
    "objectID": "posts/2023-03-05-personal-website-version-2/index.html#blog-on-a-quarto-website",
    "href": "posts/2023-03-05-personal-website-version-2/index.html#blog-on-a-quarto-website",
    "title": "Personal Website Version 2.0",
    "section": "",
    "text": "Samantha points out that a Quarto Blog is just a special point of a Quarto website. I actually got a little concerned about using Quarto as my blog because the directions of how to set up the individual posts had a lot of steps that I was worried I would not be able to do consistently over time. That‚Äôs when I thought to write a script to do it for me, and instead was saved several hours of work by Mark‚Äôs post."
  },
  {
    "objectID": "posts/2023-03-05-personal-website-version-2/index.html#giscus",
    "href": "posts/2023-03-05-personal-website-version-2/index.html#giscus",
    "title": "Personal Website Version 2.0",
    "section": "",
    "text": "Okay, so this is the main thrust of this post: Giscus. Which has painfully cute name. I was actually able to set it up on a test Quarto Book project, but of course that was months ago, and I can‚Äôt remember the process because I didn‚Äôt write it down! So for myself and for everyone else, here I go!\nFirst, why did I choose giscus? I loved that it supported multiple languages (human languages because I sometimes blog about languages that don‚Äôt use the Latin alphabet), it has some math notation ability, and it is open source and has a great github page."
  },
  {
    "objectID": "posts/2023-03-05-personal-website-version-2/index.html#giscus-steps",
    "href": "posts/2023-03-05-personal-website-version-2/index.html#giscus-steps",
    "title": "Personal Website Version 2.0",
    "section": "",
    "text": "You have to add giscus as an app on Github.\nDepending on your settings, you additionally may need to add the repo of interest to you configuration settings on giscus.\nEnable discussions on your repo (settings -&gt; features -&gt; discussions).\nGo to giscus.app and follow instructions there and it will give you some good information like repo-id which you will need to put in your _quarto.yml.\nTake the information from the giscus.app and update your _quarto.yml to include information about the repo, giscus, and some ids. Unfortunately, it is not formatted the way you need to put it into the _quarto.yml.\n\n  comments: \n    giscus:\n      repo: MaraAlexeev/personal_website_v2\n      repo-id: FAKE_REPO_ID #Get this from giscus.app\n      category: General\n      category-id: FAKE_CATEGORY_ID #Get this from giscus.app\n      mapping: title #pathname was very gross format\n      reactions-enabled: TRUE\n      input-position: bottom\n      theme: light\n\nFor pages you don‚Äôt want to have comments on put in the yaml header of that page comments: false. I do this for my blog post listing page and my about page."
  },
  {
    "objectID": "posts/2022-11-12-cod-liver-in-nine-acts/index.html",
    "href": "posts/2022-11-12-cod-liver-in-nine-acts/index.html",
    "title": "Cod Liver in Nine Acts",
    "section": "",
    "text": "Family visited recently and left us with nine cans of Icelandic Cod Liver. Why nine you ask? Well they had a box of twelve sent ahead of their visit and ate three of them while staying with us.\n\n\n\n\n\n\n\n\n\nI texted a picture of my undeserved hepatic lode of Northern Atlantic goodness to med school friends and promised culinary updates in my pursuit of full turn over of the cupboard inventory. Well, it is just too good of a joke to not take seriously. The tin also is a bit inspirational with the brand name ‚ÄúiCan‚Äù.\nI‚Äôm not a spicy food fanatic, but other than that I am try to be game for trying something at least once.\nThe process of getting these fish livers to me in tidy little tins is probably worthy of its own write up, but alas we will have to settle with Mara reviewing the end product.\nACT I\nI opened the can up and it reminded me of cat food. Cat food I would be happy to feed to my hypothetical cat, but cat food nonetheless.\n\n\n\n\n\n\n\n\n\nThe first recipe was just the product of reviewing a few Google hits and synthesizing them into something that I had the ingredients for. Hard to even call it a recipe since it was so easy to do.\nCod liver on toast\n\nCan of cod liver, drained then mashed with fork\nTwo hard boiled eggs, sliced\nChopped chives, 1 teaspoon combined with cod liver, and 2 teaspoon reserved for garnish\nSqueeze of lemon juice into mashed cod liver\nToast, buttered\nSalt to taste\n\nTop toast with mashed cod liver. Add a slice of egg and top with chives. Enjoy!\n\n\n\n\n\n\n\n\n\nReview ‚Äì Totally fine! Good even. And looked fancy. I think a high end butter would elevate it. I happened to have a fresh loaf of sourdough bread at home, and that was a very nice combo. Would consider serving this at a party like a Russian style New Year‚Äôs Eve party with lots of small appetizers. Probably would not eat a ton of these, but certainly an interesting dish with good texture.\n\n\n\n\n\n\n\n\n\nACT II-IX\nTo be continued‚Ä¶"
  },
  {
    "objectID": "posts/2021-12-05-pedestrian-nightmare/index.html",
    "href": "posts/2021-12-05-pedestrian-nightmare/index.html",
    "title": "Pedestrian Nightmare",
    "section": "",
    "text": "Big parenting fears\nOne of my biggest fears as a parent is the threat of cars to the well-being of my children. And unlike other lurking parenting fears, this one is upsetting because it is a fairly rational fear based on the causes of death and injury to children in and out of vehicles.\nI hope to learn a bit more about how my own community could make streets safer and better for folks, so putting this here as a promise to myself.\n\n\n\n\n\nNightmare interaction of pedestrian areas and cars."
  },
  {
    "objectID": "posts/2021-05-25-running-my-first-r-workshop/index.html",
    "href": "posts/2021-05-25-running-my-first-r-workshop/index.html",
    "title": "Running My First R Workshop",
    "section": "",
    "text": "Clinical Informatics Conference 2021\nI attended the virtual Clinical Informatics Conference last week, and I also did a workshop on R for Clinical Informatics. This was the first time I had ever developed material for a workshop and run a workshop. It was a solo operation, but fortunately I had some great support from my fellowship program beforehand to get prepared.\nAll the materials can be found here. Note the RStudio Cloud workspace has been turned off, but all the materials are available on that Github repo.\n\n\nPrior Experience\nI started learning R in Spring of 2019. I started reading R for Data Science and found the #rstats twitter world. Fall of 2019 I went to my first conference about R, R/Medicine, which I now help plan! At that 2019 R/Medicine conference I went to my first workshop‚ÄîR Markdown for Medicine, which was taught by the amazing Dr.¬†Alison Hill.\n\n\nPlanning\nI spent rough two entire work days planning the submission to CIC in January 2021. This includes all the false start ideas I had before settling on the workshop idea. This including a skeleton of some of the actual material I ended up using.\nMy final submission and eventual project used simulated data that one might have while doing a Quality Improvement project to show how one could use R for the entire process or pieces of it.\nI then spent 1.5 days creating the first draft of the material in mid-April. I presented my draft to my fellowship group, got amazing feedback, and then spent another 1.5 days incorporating the feedback for that. I was able to ignore it for a few days, and then polished off the final slides that had to be submitted in a PDF format for the pre-conference materials. I then spent about another day polishing off html slides to include some nicer formatting and some ggplots, finished the materials for the attendees to do, setting everything up on RStudio Cloud, and pushing everything to a nice Github page.\n\n\nWorkshop\nThe workshop was held on zoom. Let me just say how thankful I am to the few people who kept their cameras on and/or who spoke. It is such wonderful feedback in the video conference isolation chamber to hear from people so you can help and adapt during the conference.\nI was initially worried that the material I had and the amount was too little. I think this is unlikely to be true for me in the future! I had 100 ideas I wanted to share, but fortunately after doing a dry run with folks to my program, I was able to really trim it down to the core basics I wanted to share with some accessible extras of more advanced features.\nRStudio Cloud worked great, and no one had technical issues that they shared with me.\nOne funny thing that happened as we were walking through the examples in the prepared .Rmd, is that I discussed packages and libraries, but I forgot to tell people to run that code chunk! Fortunately, someone spoke up relatively quickly and I could tell folks to do that. As an instructor, it is amazing how quickly you can forget how very not intutive the basics of coding are.\nI believe about 50 people registered for the workshop and 25 were there for any portion, and then had a solid base of 20 people for most of the workshop.\nI did a survey about people‚Äôs experience with programming and R:\n\nAbout 50% of people had every programmed before in ANY language\n40% of people had ever used R before\n40% had used RStudio before (presumably the same 40%?)\n\nPeople‚Äôs goals for the workshop ranged from seeing what R was to learning how to do specific types of plots in ggplot for their quality improvement projects.\n\n\nAfterthoughts\nI loved it. I had a great time, and I learned a ton about how to present. It was great to hear questions from folks because it forced me to give very simple, clear responses which sometimes improved my understanding.\nPeople asked really great questions, some of which I didn‚Äôt know the answer at the time. For example, is RStudio Cloud HIPPA compliant. Answer: No! But there are other services that are that you could use R and RStudio on.\n\n\nDo better next time\nI took notes on what to do differently next time!\n\nHave a better way to give my contact information (on the Github page)\nMove the slides about how to knit to the point in the workshop that people will need it\nAdd more real world examples of how R is or could be used in medicine\nFigure out how folks use R and RStudio in HIPAA compliant ways\nGive post-workshop tips\n\nHow to download R and RStudio\nMake a RStudio project\nClone a Github repo\nStart a Github issue\n\nShow survey results"
  },
  {
    "objectID": "posts/2019-09-02-goals-as-a-chief-resident/index.html",
    "href": "posts/2019-09-02-goals-as-a-chief-resident/index.html",
    "title": "Goals as a chief resident",
    "section": "",
    "text": "Introduction\n\n\nConclusion"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Let‚Äôs learn something interesting",
    "section": "",
    "text": "Let‚Äôs learn something interesting\nWhile I am not a fan of the words used in a certain meme that sounds a wee bit like ‚ÄúFiddle around, find out‚Äù I am a strong believer that learning by doing is the most effective method to learn. I love that the original meme implies that the input to the finding out can be low quality. However, I think the there is room for a second part of the process captured by the phrase ‚Äútear down, build up‚Äù.\nThe initial discovery is rewarding, but a further process of tearing it apart and building something from your learning is delightful. I believe most of my life I have held back from doing and sharing many such investigations because I did not believe I could contribute anything interesting.\nI understand now, that it doesn‚Äôt matter at all if I contribute anything wider than my own improvement because my improvement is the worthwhile goal. With my ideas made out in the world, they can be refined or discarded. But thus exposed, I am open to the judgment of others and their criticisms, yet I have had the courage to put words down. Hopefully, finding out better conclusions.\nFrom Hegel,\n\nA will which resolves on nothing is not an actual will; the characterless man can never resolve on anything. The reason for such indecision may also lie in an over-refined sensibility which knows that, in determining something, it enters the realm of finitude, imposing a limit on itself and relinquishing infinity; yet it does not wish to renounce the totality which it intends. Such a disposition is dead, even if its aspiration is to be beautiful. ‚ÄòWhoever aspires to great things‚Äô, says Goethe, ‚Äòmust be able to limit himself.‚Äô Only by making resolutions can the human being enter actuality, however painful the process may be; for inertia would rather not emerge from that inward brooding in which it reserves a universal possibility for itself. But possibility is not yet actuality. The will which is sure of itself does not therefore lose itself in what it determines.\n\nSo time to find out."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Who am I?\nMy name is Mara Alexeev. I currently live in Athens, Georgia, but I grew up on a farm in central Iowa. In fourth grade I was in love with space and wanted to be a part time astronaut and part time farmer.\nIn the summer of 2022, I finished a masters in Biomedical Informatics at Harvard Medical School and a fellowship in Clinical Informatics at Boston Children‚Äôs Hospital. My primary medical specialty is Pediatrics.\nCurrently, I am the Director of Clinical Informatics at a health tech start up called Layer Health.\nI love learning human and computer languages. I‚Äôve had a long love affair with Russian and German, and interested in American Sign Language (and also the Russian Manual Alphabet!), and casually learning a bit of Latin and Spanish.\nAt home you can find me reading, cooking, in the garden, and chasing my children around.\n\n\n\nMara at the Tandy, age 3"
  },
  {
    "objectID": "posts/2019-08-30-the-first-post-of-the-new-website/index.html",
    "href": "posts/2019-08-30-the-first-post-of-the-new-website/index.html",
    "title": "The first post of the new website",
    "section": "",
    "text": "Note from March 2023: This post describes my migration from Squarespace to a blogdown website in August 2019. I migrated again in March 2023 from blogdown to a quarto website.\nThis is my first post on my new website built with the R package blogdown, the help of many online help pages, and my lovely husband. I am using Github and Netlify as well. I don‚Äôt have the energy to write a post about how I built this, but here is the list of things that caused pain:\n\nin my config.toml file I had replaced the baseurl default of baseurl = \"/\" with baseurl = \"https://www.maraalexeev.com\"\nthis causes problems so just keep it as the /\non Netlify there is a deploy setting that I did incorrectly so my page worked locally but not online\nAnswer here\nsomehow I got a post on my page from 1 AD (suspect no date was included on something), I renamed my file from a foo.Rmarkdown to foo.Rmd and the problem went away, but I can‚Äôt be certain that I didn‚Äôt also do something else in my quest.\nTip here\n\nOverall, this was an amazing but slightly frustrating experience with most of the frustration being at the deployment phase. Now that I have site up and running, I am beyond excited to start doing more with it. I especially am excited about figuring out how to have my data easily accessible for someone re-running my analysis in something that I post.\nA few quick things that I hope to do soon are:\n\nUnderstand more of what an R project means and how to use it in my workflow\nFigure out how to store files and content in a reasonable method\nGet amazing at Rmarkdown\nUpload old content from my previous website"
  },
  {
    "objectID": "posts/2019-09-12-r-medicine-2019-conference-day-1/index.html",
    "href": "posts/2019-09-12-r-medicine-2019-conference-day-1/index.html",
    "title": "2019 R-Medicine Conference Day 1",
    "section": "",
    "text": "R Markdown for Medicine\nAttended a workshop by Alison Hill. Here are some of my notes to future self to play with later.\n\nFigure Labeling automatically\ndistill package\nhtml_document2 yaml output\nxaringan\nposterdown\nstargazer\ntable making\ndifferent themes (berlin, roma)\nproject management\nflexdashboard\nredoc\nspelling\nwordcountaddin\nhtmlwidgets for R\nleaflet\ngitlab\nDataTables\nrevealjs\n\n\n\nFigure out how to‚Ä¶\n\nBookdown: how to combine multiple .Rmd into a ‚Äúbook‚Äù\nMake a powerpoint presenation from Rmarkdown (my work is heavy in ppt)\n\n\n\nBest practices\n\nProject\nUse here package\nHave a folder for figures to print to and save\n\n\n\nHealthcare Specific R Packages\n\nqicharts\nqcc\ncomorbidity\n\n\n\nMake a table in Rmarkdown\n\n\n\nColumn 1 left justify\nColumn 2 centered\nColumne 3 right justified\n\n\n\n\nA\nB\nC\n\n\n\nHoly cow, that worked on the first try!\n\n\nPets not Livestock\nAlison Horst advised us that if our figures are more like pets than livestock, we should name them!!!\nHere‚Äôs my attempt to name some figures and link them throughout the document.\n\n\nCode\nlibrary(tidyverse)\n\n\nWarning: package 'tidyverse' was built under R version 4.4.3\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'dplyr' was built under R version 4.4.3\n\n\nWarning: package 'stringr' was built under R version 4.4.3\n\n\nWarning: package 'forcats' was built under R version 4.4.3\n\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.2\n‚úî ggplot2   3.5.2     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.1\n‚úî purrr     1.0.4     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\nCode\nbar_graph_mtcars &lt;- ggplot(mtcars, aes(x = drv)) + geom_bar()\n\n\n\n\nResources\n\nhttps://commonmark.org/help/\nhttps://rmd4medicine.netlify.com"
  },
  {
    "objectID": "posts/2021-11-08-alt-responses-to-give-the-god-of-death/index.html",
    "href": "posts/2021-11-08-alt-responses-to-give-the-god-of-death/index.html",
    "title": "Alt Responses to Give the God of Death",
    "section": "",
    "text": "‚ÄúThere is only one god and his name is death. And there is only one thing we say to death: Not today.‚Äù\n‚Äï Syrio Forel (Game of Thrones S1:Ep6: A golden crown)\n\nWhile Game of Thrones fans are fond of refusing the God of Death, Wikipedia has lots of data about people who did say: Ok, today is the day.\n\nInspiration\nIn July 2020, my husband presented me with two tweets about change of the average age of death over time (tweet 1 and tweet 2) and challenged me to make some cooler graphs.\n\n\n\n\n\n\n\n\n\n\n\n\nMotivations\nWith this post, I want to do three things:\n\nSee if I could make more engaging graphs than the original twitter post using R\nLearn to pull data from Wikidata using the {WikidataQueryServiceR} package\nVisualize the differences between males and females in the data\n\nI work in healthcare data, so often I cannot share my data or analysis for privacy reasons. This post is my way to share some of the techniques I use at work with data that CAN see the light of day.\nHere I will walk you start to finish, from data pull to pretty plots, to give you some inspiration for your own data analysis projects.\n\n\nData sources\nI originally started working on this analysis and blog post on July 22, 2020, so I have learned a lot of data analytic and programming skills since then, but at the time I had never written a SQL (or one of the many similar SQL-like languages) query outside of an online programming tutorial.\nThis is the command I used to grab the data from the Wikidata Query Service on November 6, 2021 using the {WikidataQueryServiceR} package.\n\n\nCode\nmy_wiki_query &lt;- query_wikidata('SELECT ?item ?dob ?dod ?sex_or_gender WHERE {\n  ?item wdt:P31 wd:Q5;\n  OPTIONAL { ?item wdt:P570 ?dod }\n  OPTIONAL { ?item wdt:P569 ?dob }\n  OPTIONAL { ?item wdt:P21 ?sex_or_gender. }\n}')\n\n\nWith this short command, I was able to quite effortlessly pull data on 3207218 records.\nAs I started out learning R and playing with data, I knew nothing about querying publicly available sources of data. Being able to pull over 3 million rows of data for a toy project is an amazing feat!\nIf you are just starting out in learning R or want to find some great pre-cleaned datasets to work with, check out Tidy Tuesday and follow people‚Äôs work on twitter using the #TidyTuesday hashtag.\n\n\nUnderstanding the data\nThe first question I had about the distribution of data on time and by year. I decided to limit myself to the year 1000 onward to be somewhat comparable to the tweets that inspired this post. Here I created a plot to show the distribution of births counts by birth year.\n\n\n\n\n\n\n\n\n\nSome notable things about the data is the increase of number of available records over time and with an expected drop off as the birth year gets closer to the current year.\nI expected a drop off because it takes most people a certain number of years of life to become notable enough to get a Wikipedia page. While I don‚Äôt do this here, I think it would be an interesting analysis to calculate the average age at which a person receives an entry to Wikipedia.\nA fun sub-analysis would to examine differences in the ages by category of notability. For example, I expect that athletes would have a younger age of first entry compared to Nobel Laureates.\nAnother notable trend is that the birth count is high at the start of centuries (eg 1100) compared to intervening years with blunting of that phenomenon from 1500 onward and disappearing around 1800. My instinct is that this reflects the improvement in record keeping and preservation as we approach modern times.\n\n\nSex based differences\nMy prediction prior to exploring the distribution is that women are represented at lower rates in the data compared to men. Graphing the data confirms this. I suppose the surprising insight from the graph is that the proportion of women represented in the data from about 1500 to 1800 is so consistent.\n\n\n\n\n\n\n\n\n\n\n\nAverage age of death\nI considered two ways to visualize the average of death. The first way is by grouping birth year and seeing the average age of death for that group. As you can see in the graph below, the major issue with that approach is that years close to the present will have very low average ages for death. This happens because in years less than roughly 80 years prior to 2021, anyone who has died, died relatively ‚Äòyoung‚Äô.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo avoid this problem, I instead grouped by death year to show the average age of death for people who died in that year. From these plots we see the average age of death for women flips to be higher than men in the early 20th century and continues until present time.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo compare to tweet 1, I need to exclude deaths that occurred at 20 or under. By examining my plot verses that tweet, it is difficult to compare because I don‚Äôt know what smoothing function that the person used to calculate their line. The data before about 1600 has much more variability that data after that point.\n\n\n\n\n\n\n\n\n\nGiven this, I then investigated what the average age of death looks like from 1600 onward.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinally, let‚Äôs look at the data from 1800 onward to investigate the huge expected impacts of both World Wars. While I expected to see the huge impact on age of death in the years 1914 - 1918 and 1939 - 1945, I was surprised to see that the average age of death for both men and women was so affected. I anticipated that men, who are the primary actors in military actions, would have taken a bigger hit than women. While beyond the scope of this post, I think there might be something mysterious going on in the data around the turn of the 21st century with a spike upwards in both sex‚Äôs average age of death.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDirty data\nSpeaking of data issues, the final part of my analysis I‚Äôd like to share is how many birth dates are represented at higher rates than expected. As mentioned above, before 1800, many people had birth years listed as years like 1000 or 1300. Here I‚Äôll also show how uncertainty of the day of births can be seen in the data.\nThe plot below shows a yellow dot for date that has a 10% or greater number of birth dates than expected under the (somewhat tenuous) assumption that birth days will be distributed equally throughout the year. Notice the nearly straight lines on the y-axis which represents birth dates that fall on the start of a month.\n\n\n\n\n\n\n\n\n\nDifficult to see on the graph above, but here is a zoomed in version looking only at January birth dates. Here you can see that January 1st is over-represented in the data for literally ever year in the data from 1000 to 2021!\n\n\n\n\n\n\n\n\n\n\n\nWrap up\nI hope you have enjoyed my mini-journey of exploring the average age of the death over time. It only took me 17 months to finally finish it!\nWhat I hope I can do in future posts is look at data for people beyond those notable enough to have Wikidata entries to see the difference in life expectancies for those more and less notable.\n\n\nTechnical notes\nFor anyone wanting to reproduce my work, you can see my raw code below as well as my R session information. If you repeat the analysis, your data will likely be different than mine as the data pull for this post was done on November 6, 2021.\n\n\nCode\nlibrary(tidyverse)\nlibrary(WikidataQueryServiceR)\nlibrary(lubridate)\nlibrary(stringr)\nlibrary(magrittr)\nlibrary(plotly)\nlibrary(DT)\nlibrary(scales)\nlibrary(ggthemes)\n\nmy_wiki_query &lt;- query_wikidata('SELECT ?item ?dob ?dod ?sex_or_gender WHERE {\n  ?item wdt:P31 wd:Q5;\n  OPTIONAL { ?item wdt:P570 ?dod }\n  OPTIONAL { ?item wdt:P569 ?dob }\n  OPTIONAL { ?item wdt:P21 ?sex_or_gender. }\n}')\n\nmy_wiki_query &lt;- readRDS(\"./data/my_wiki_query.rds\")\n\ncount_query &lt;- nrow(my_wiki_query)\n\n# sex notation\nmy_wiki_query %&lt;&gt;% \n  mutate(simplified_sex = case_when(\n    sex_or_gender == \"http://www.wikidata.org/entity/Q6581072\" ~ 1, #female\n    sex_or_gender == \"http://www.wikidata.org/entity/Q6581097\" ~ 2, #male\n    TRUE ~ 3 #not female, not male\n    ))\n\nmy_wiki_query %&lt;&gt;% \n  dplyr::distinct(item, .keep_all= TRUE) %&gt;% \n  dplyr::mutate(full_year_of_birth = str_extract(dob, \"-?[:digit:]{4}\")) %&gt;% \n  dplyr::mutate(full_year_of_death = str_extract(dod, \"-?[:digit:]{4}\")) %&gt;% \n  dplyr::mutate(approx_age_at_death = as.numeric(full_year_of_death) - as.numeric(full_year_of_birth)) \n\nmy_wiki_query$full_year_of_birth &lt;- as.numeric(my_wiki_query$full_year_of_birth) \nmy_wiki_query$full_year_of_death &lt;- as.numeric(my_wiki_query$full_year_of_death)   \nmy_wiki_query$simplified_sex &lt;- as_factor(my_wiki_query$simplified_sex)\n\nmy_wiki_query %&lt;&gt;% mutate(decade_birth = full_year_of_birth %/% 10)\nmy_wiki_query %&gt;% \n  filter(full_year_of_birth &gt;= 1000 & full_year_of_birth &lt; 2022) %&gt;% \n  filter(simplified_sex == 1 | simplified_sex == 2) %&gt;% \n  ggplot(aes(x = full_year_of_birth)) +\n  geom_histogram(binwidth = 10) +\n  scale_y_log10(breaks=c(100, 1000, 10000, 100000), labels = c(\"100\", \"1000\", \"10,000\", \"100,000\")) +\n  scale_x_continuous(breaks = seq(1000, 2021, 100)) +\n  theme_economist() + \n  labs(title = \"Distribution of births per year\",\n       x = \"Year\",\n       y = \"Birth count per year\",\n       subtitle = \"Years 1000 to 2021\\nLog Scale Y-axis\", \n       caption = \"Including only records with birth years,\\nand restricted to sex of either male or female.\") +\n  coord_cartesian(ylim = c(100, 200000))\nmale_color &lt;- \"#2E45B8\"\nfemale_color &lt;- \"#C91D42\"\n\nsex_proportion_plot &lt;- my_wiki_query %&gt;% \n  filter(simplified_sex == 1 | simplified_sex == 2) %&gt;% \n  filter(full_year_of_birth &gt;= 1000 & full_year_of_birth &lt; 2021) %&gt;% \n#  group_by(decade_birth) %&gt;% \n  ggplot(aes(x = full_year_of_birth, fill = simplified_sex, color = simplified_sex)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(labels = c(\"Female\", \"Male\"), values = c(female_color, male_color)) +\n  scale_color_manual(labels = c(\"Female\", \"Male\"), values = c(female_color, male_color)) +\n  labs(title = \"Proportion of men and women over time in birth cohorts\", \n       x = \"Year of birth\",\n       y = \" \", \n       fill = \"Sex\", \n       color = NULL) +\n  geom_hline(yintercept = 0.5) +\n  theme_economist() +\n  scale_y_continuous(breaks=c(0, 0.25, .5, 0.75, 1), \n                     labels = c(\" \", \" \", \"50%\", \" \", \" \")) +\n  scale_x_continuous(breaks = seq(1000, 2021, 100)) +\n  guides(color = \"none\")\n\nsex_proportion_plot\nce_dates &lt;- my_wiki_query %&gt;% \n  filter(full_year_of_birth &gt;= 1000 & full_year_of_birth &lt;= 2021) %&gt;% \n  filter(full_year_of_death &gt;= 1000 & full_year_of_birth &lt;= 2021) %&gt;% \n  mutate(date_of_birth = as_date(dob)) %&gt;%\n  mutate(year_birth = year(date_of_birth)) %&gt;%\n  mutate(month_birth = month(date_of_birth)) %&gt;%\n  mutate(day_birth = day(date_of_birth)) %&gt;%\n  mutate(date_of_death = as_date(dod)) %&gt;%\n  mutate(year_death = year(date_of_death)) %&gt;%\n  mutate(month_death = month(date_of_death)) %&gt;%\n  mutate(day_death = day(date_of_death)) %&gt;%\n  mutate(lifespan = as.duration(interval(date_of_birth, date_of_death))) %&gt;% \n  filter(lifespan &lt; years(123)) %&gt;% \n  filter(lifespan &gt;= years(0))\naverage_lifespan_by_sex &lt;- ce_dates %&gt;% \n  group_by(year_birth, simplified_sex) %&gt;% \n  summarise(average_age = mean((lifespan)))\n\naverage_lifespan &lt;- ce_dates %&gt;% \n  group_by(year_birth) %&gt;% \n  summarise(average_age = mean((lifespan)))\n\nplot_average_lifespan &lt;- average_lifespan %&gt;%  \n  ggplot(aes(x = year_birth, y = (average_age/31557600))) +\n  geom_smooth(color =   \"#F97A1F\") +\n  geom_point(alpha = 0.05, color =  \"#F97A1F\") +\n  labs(title = \"Average age of death over time\",\n       x = \"Birth Year Cohort\",\n       y = \"Age\") \n\nplot_average_lifespan + theme_economist() + scale_x_continuous(breaks = seq(1000, 2021, 100))\n\naverage_lifespan_by_sex &lt;- ce_dates %&gt;% \n  group_by(year_birth, simplified_sex) %&gt;% \n  summarise(average_age = mean((lifespan)))\n\nplot_average_lifespan_by_sex &lt;- average_lifespan_by_sex %&gt;% \n  filter(simplified_sex != 3) %&gt;% \n  ggplot(aes(x = year_birth, y = (average_age/31557600), color = simplified_sex)) +\n  geom_smooth() +\n  geom_point(alpha = 0.05) +\n  scale_color_manual(labels = c(\"Female\", \"Male\"), values = c(female_color, male_color)) +\n  labs(title = \"Average age of death over time by sex\",\n       x = \"Birth Year Cohort\",\n       y = \"Age\", \n       color = \"Sex\") \n\nplot_average_lifespan_by_sex + theme_economist() + scale_x_continuous(breaks = seq(1000, 2021, 100)) \naverage_lifespan_by_sex_dc &lt;- ce_dates %&gt;% \n  group_by(year_death, simplified_sex) %&gt;% \n  summarise(average_age = mean((lifespan)))\n\naverage_lifespan_dc &lt;- ce_dates %&gt;% \n  group_by(year_death) %&gt;% \n  summarise(average_age = mean((lifespan)))\n\nplot_average_lifespan_dc &lt;- average_lifespan_dc %&gt;%  \n  ggplot(aes(x = year_death, y = (average_age/31557600))) +\n  geom_smooth(color =   \"#F97A1F\") +\n  geom_point(alpha = 0.05, color =  \"#F97A1F\") +\n  labs(title = \"Average age of death over time\",\n       x = \"Death Year Cohort\",\n       y = \"Age\") \n\nplot_average_lifespan_dc  + theme_economist() + scale_x_continuous(breaks = seq(1000, 2021, 100))\n\nplot_average_lifespan_by_sex_dc &lt;- average_lifespan_by_sex_dc %&gt;% \n  filter(simplified_sex != 3) %&gt;% \n  ggplot(aes(x = year_death, y = (average_age/31557600), color = simplified_sex)) +\n  geom_smooth() +\n  geom_point(alpha = 0.05) +\n  scale_color_manual(labels = c(\"Female\", \"Male\"), values = c(female_color, male_color)) +\n  labs(title = \"Average age of death over time by sex\",\n       x = \"Death Year Cohort\",\n       y = \"Age\", \n       color = \"Sex\") \n\nplot_average_lifespan_by_sex_dc + theme_economist() + scale_x_continuous(breaks = seq(1000, 2021, 100))\naverage_lifespan_dc_20 &lt;- ce_dates %&gt;% \n  filter(lifespan &gt; 630720000) %&gt;% \n  group_by(year_death) %&gt;% \n  summarise(average_age = mean((lifespan)))\n\nplot_average_lifespan_dc_20 &lt;- average_lifespan_dc_20  %&gt;%  \n  ggplot(aes(x = year_death, y = (average_age/31557600))) +\n  geom_smooth(color =   \"#F97A1F\") +\n  geom_point(alpha = 0.05, color =  \"#F97A1F\") +\n  labs(title = \"Average age of death over time\",\n       subtitle = \"Only lifespans greater than 20 years\",\n       x = \"Death Year Cohort\",\n       y = \"Age\") \n\nplot_average_lifespan_dc_20 + theme_economist() + scale_x_continuous(breaks = seq(1000, 2021, 100))\nplot_average_lifespan_dc &lt;- average_lifespan_dc %&gt;%  \n  filter(year_death &gt;= 1600) %&gt;% \n  ggplot(aes(x = year_death, y = (average_age/31557600))) +\n  geom_smooth(color =   \"#F97A1F\") +\n  geom_point(alpha = 0.05, color =  \"#F97A1F\") +\n  labs(title = \"Average age of death over time\",\n       x = \"Death Year Cohort\",\n       y = \"Age\") \n\nplot_average_lifespan_dc + \n  theme_economist() + \n  scale_x_continuous(breaks = seq(1000, 2021, 100)) + \n    coord_cartesian(ylim = c(40, 90))\n\nplot_average_lifespan_by_sex_dc &lt;- average_lifespan_by_sex_dc %&gt;% \n  filter(year_death &gt;= 1600) %&gt;% \n  filter(simplified_sex != 3) %&gt;% \n  ggplot(aes(x = year_death, y = (average_age/31557600), color = simplified_sex)) +\n  geom_smooth() +\n  geom_point(alpha = 0.05) +\n  scale_color_manual(labels = c(\"Female\", \"Male\"), values = c(female_color, male_color)) +\n  labs(title = \"Average age of death over time\",\n       x = \"Death Year Cohort\",\n       y = \"Age\", \n       color = \"Sex\") +\n  guides(color = \"none\")\n\nplot_average_lifespan_by_sex_dc + \n  theme_economist() + \n  scale_x_continuous(breaks = seq(1000, 2021, 100)) + \n  coord_cartesian(ylim = c(40, 90))\nyear_cutoff &lt;- 1800\n\nplot_average_lifespan_dc &lt;- average_lifespan_dc %&gt;%  \n  filter(year_death &gt;= year_cutoff) %&gt;% \n  ggplot(aes(x = year_death, y = (average_age/31557600))) +\n  geom_line(color =     \"#F97A1F\") +\n # geom_point(alpha = 0.05, color =     \"#F97A1F\") +\n  labs(title = \"Average age of death over time\",\n       x = \"Death Year Cohort\",\n       y = \"Age\") \n\nplot_average_lifespan_dc + \n  theme_economist() + \n  scale_x_continuous(breaks = seq(1000, 2021, 100)) + \n    coord_cartesian(ylim = c(40, 90))\n\nplot_average_lifespan_by_sex_dc &lt;- average_lifespan_by_sex_dc %&gt;% \n  filter(year_death &gt;= year_cutoff) %&gt;% \n  filter(simplified_sex != 3) %&gt;% \n  ggplot(aes(x = year_death, y = (average_age/31557600), color = simplified_sex)) +\n  geom_line() +\n  scale_color_manual(labels = c(\"Female\", \"Male\"), values = c(female_color, male_color)) +\n  labs(title = \"Average age of death over time by sex\",\n       x = \"Death Year Cohort\",\n       y = \"Age\", \n       color = \"Sex\") +\n  guides(color = \"none\")\n\nplot_average_lifespan_by_sex_dc + \n  theme_economist() + \n  scale_x_continuous(breaks = seq(1000, 2021, 100)) + \n  coord_cartesian(ylim = c(40, 90))\n\n\nheatmap_dates &lt;- ce_dates %&gt;% \n  mutate(pad_month_birth = str_pad(month_birth, width = 2, side = \"left\", pad = 0)) %&gt;% \n  mutate(pad_day_birth = str_pad(day_birth, width = 2, side = \"left\", pad = 0)) %&gt;% \n  unite(\"heatdate\", c(year_birth, pad_month_birth, pad_day_birth), sep = \"-\", remove = FALSE) %&gt;% \n  mutate(doy = lubridate::yday(as_date(heatdate)))\n\nheatmap_dates_subset &lt;- heatmap_dates %&gt;% dplyr::select(year_birth, heatdate, doy)\n\nheatmap_data &lt;- heatmap_dates_subset %&gt;% \n  group_by(year_birth, doy) %&gt;% \n  summarise(count = n()) %&gt;% \n  ungroup() %&gt;% \n  group_by(year_birth) %&gt;% \n  mutate(year_total = sum(count)) %&gt;% \n  mutate(proportion_year = count/year_total) %&gt;% \n  mutate(too_high = case_when(\n    proportion_year &gt; 0.003 ~ 1, #roughly 10% higher than expected\n    TRUE ~ 0\n  ))\n\n\ntoo_many_births_plot &lt;- heatmap_data  %&gt;% \n  filter(year_birth &gt;= 1500) %&gt;% \n  ggplot(aes(x = year_birth, y = doy, fill = too_high, text = )) + \n  geom_tile() +\n  scale_fill_gradient(low = \"#475ED1\", high = \"#F9C31F\") + # mid \n  theme_economist() +\n  theme(legend.position = \"none\") +\n  labs(x = \"Year\", \n       y = \" \", \n       title = \"Days of the year with more than expected birthdates\",\n       subtitle = \"Yellow represents with \\\"too\\\" many births \\nY-axis is the day of the year with tick marks to show the start of the month\") +\n  scale_y_continuous(breaks=c(1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335),\n                     labels = c(\"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\", \"O\", \"N\", \"D\"))\n\ntoo_many_births_plot\ntoo_many_births_plot &lt;- heatmap_data  %&gt;% \n  filter(doy &lt; 31) %&gt;% \n  ggplot(aes(x = year_birth, y = doy, fill = too_high, text = )) + \n  geom_tile() +\n  scale_fill_gradient(low = \"#475ED1\", high = \"#F9C31F\") + # mid \n  theme_economist() +\n  theme(legend.position = \"none\") +\n  labs(x = \"Year\", \n       y = \" \", \n       title = \"Days of the year with more than expected birthdates\",\n       subtitle = \"Yellow represents with \\\"too\\\" many births \\nY-axis is the day of the year with tick marks to show the start of the month\") +\n  scale_y_continuous(breaks=c(1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335),\n                     labels = c(\"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\", \"O\", \"N\", \"D\"))\n\ntoo_many_births_plot\n\nsessionInfo()\nimage_for_blog_post &lt;- plot_average_lifespan_by_sex_dc + \n    theme_economist() + \n     scale_x_continuous(breaks = seq(1000, 2021, 100)) + \n     coord_cartesian(ylim = c(40, 90))\n\nggsave(file = \"./images/image_for_blog_post.png\" )\n\n\n\n\nCode\nsessionInfo()\n\n\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] ggthemes_5.1.0              scales_1.4.0               \n [3] DT_0.33                     plotly_4.11.0              \n [5] magrittr_2.0.3              WikidataQueryServiceR_1.0.0\n [7] lubridate_1.9.4             forcats_1.0.0              \n [9] stringr_1.5.2               dplyr_1.1.4                \n[11] purrr_1.0.4                 readr_2.1.5                \n[13] tidyr_1.3.1                 tibble_3.2.1               \n[15] ggplot2_3.5.2               tidyverse_2.0.0            \n\nloaded via a namespace (and not attached):\n [1] generics_0.1.4     lattice_0.22-6     stringi_1.8.4      hms_1.1.3         \n [5] digest_0.6.37      evaluate_1.0.3     grid_4.4.2         timechange_0.3.0  \n [9] RColorBrewer_1.1-3 fastmap_1.2.0      Matrix_1.7-1       jsonlite_2.0.0    \n[13] httr_1.4.7         mgcv_1.9-1         viridisLite_0.4.2  lazyeval_0.2.2    \n[17] cli_3.6.4          rlang_1.1.5        splines_4.4.2      withr_3.0.2       \n[21] yaml_2.3.10        tools_4.4.2        tzdb_0.5.0         ratelimitr_0.4.2  \n[25] assertthat_0.2.1   vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n[29] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2      gtable_0.3.6      \n[33] glue_1.8.0         data.table_1.17.6  xfun_0.52          tidyselect_1.2.1  \n[37] rstudioapi_0.17.1  knitr_1.50         farver_2.1.2       nlme_3.1-166      \n[41] htmltools_0.5.8.1  labeling_0.4.3     rmarkdown_2.29     compiler_4.4.2    \n\n\n\n\nCode\nimage_for_blog_post &lt;- plot_average_lifespan_by_sex_dc + \n    theme_economist() + \n     scale_x_continuous(breaks = seq(1000, 2021, 100)) + \n     coord_cartesian(ylim = c(40, 90))\n\nggsave(file = \"./images/image_for_blog_post.png\" )\n\n\nSaving 7 x 5 in image"
  },
  {
    "objectID": "posts/2022-10-30-the-prize/index.html",
    "href": "posts/2022-10-30-the-prize/index.html",
    "title": "The Prize",
    "section": "",
    "text": "The Prize\nI read The Prize: The Epic Quest for Oil, Money, and Power by Daniel Yergin two plus years ago while in the haze of a new baby and starting a masters and doing a fellowship, so a book report written at that time would probably be a patchy effort at best. Thus a book report written two years later is most certainly entirely suspect. However, I loved the book, and I now recommend it to anyone who will let me get to the point in a conversation where we are talking books.\n\n\nSelected unpolished thoughts\n\nhow much energy enables our modern life\nhow much oil is a national security concern\nwhy oil geography is wrapped up in wars\nthat the Nazis and Japanese Empire lost WWII in part because of energy insufficiency\nhow amazing the logistics of oil refinement and distribution are\nhow the needs of the oil industry created the most complicated and capable organizations in the world because they had the thing everyone wanted everywhere and there was a ton of competition\noil is power, figuratively\nmaybe most people don‚Äôt understand at all how important oil is because I certainly didn‚Äôt before I read the book\nhow crazy the personalities were in the history of oil and how different strategies worked or did not work\nunderstanding nationalism more in the context of industrial ‚Äòimperialism‚Äô\nimportance of human capital (an oil poor country like they Netherlands is a business powerhouse because it has talented people working on them problem) and knowledge infrastructure\nif some countries were able to get (and were not actively thwarted by external forces) themselves together they could be much better, bigger world players\nrelated to that, how delicate the policies and relationships can be between companies and the country they are operating in (eg Mexico getting angry and nationalizing the oil, but if that happens then no company will ever want to go there again and then they won‚Äôt be able to profit from their natural resources). Trump picking Rex Tiller as Secretary of State made much more sense after reading this book because I realized how much an Oil Company is like a country with little enclaves in many countries and assets in many (pipelines) and a non military ‚Äúnavy‚Äù.\nthe amazing pressure oil companies self imposed on themselves to decrease drilling and improve well conditions and the terrible conditions that were created by competing operators drilling too much into fields and causing the fields to fail prematurely because of destruction of the favorable conditions for extraction\nthe amazing technology that came out of the necessities of the oil industry\n\nQuestions I still don‚Äôt understand:\n\nwhy hydrocarbon companies aren‚Äôt leading the charge into nuclear energy?\nwho benefits from the public sentiment of ‚Äúbig bad oil‚Äù when literally everyone in the US is using their products in many parts of their lives\nwith the oil spills that have happened, is this a lot or is this not a lot (the process sounds completely terrifying) given the complexity of the process and inherent danger in a operation of such scale with hydrocarbons and involving so many natural factors (eg the oil field, ice bergs, hurricanes)\nwhy so many of the countries with this amazing resource are so poorly managed or have such repressive regimens (this is addressed but probably needs its own book!)\n\n\n\nFuture reading\nNext on my reading lists will be some of Yergin‚Äôs subsequent books. I will try to do better note take for future posts."
  },
  {
    "objectID": "posts/2023-02-26-a-sticky-bun-but-not-every-day/index.html",
    "href": "posts/2023-02-26-a-sticky-bun-but-not-every-day/index.html",
    "title": "A sticky bun, but not every day",
    "section": "",
    "text": "In the summer of 2020 we moved to Brookline, MA. Our routine immediately developed that we would do daycare drop off and then stop by Temptations Cafe (Hi Nassib!!) We particularly enjoyed their sticky buns, but it took us about 128 trips to the cafe on 108 dates to recognize the pattern of when sticky buns were available or not.\nHere I have made a github style waffle plot, that I believe makes the pattern of when sticky buns are available clearer. We finally noticed what the pattern was in October, when the days sticky buns were available increased.\nI copied the gh_waffle function from Matti Vuorre‚Äôs blog post with some minor modifications."
  },
  {
    "objectID": "posts/2023-03-12-updates-to-shiny-app-for-creating-blog-posts/index.html",
    "href": "posts/2023-03-12-updates-to-shiny-app-for-creating-blog-posts/index.html",
    "title": "Updates to Shiny App for Creating Blog Posts",
    "section": "",
    "text": "Updates on Shiny App\nLast week I wrote about how I found someone else who had written a Shiny app to create blog posts with a small amount of manual input, like the title of the post, and the app would then create the necessary files for the Quarto website format and start the post with a predetermined template with the components you added into the Shiny app.\nThis weekend while I was transferring more posts over from my old website, I noticed a few annoying and related features.\nMy posts‚Äôs folders were named something like this 2023-01-01-This Test Post is Amazing, but then my URL paths when I rendered my website were awful looking like website.com/2023-01-01-This%20Test%20Post%20is%20Amazing. Also, if I tried to include some types of punctuation, like a colon, in my title, which is the source of the folder name and URL, it would break my Shiny app.\nSolution: I added a ‚Äúslugifying‚Äù part to my Shiny App:\nslug = stringr::str_replace_all(stringr::str_to_lower(title), \"[^[:alnum:]]\", \"-\")\nNow the transformed version of the title, the slug, doesn‚Äôt have any punctuation except for dashes or capital letters, so now the URLs and folder names look much better. Also, my title can have ‚Äúspecial‚Äù punctuation without breaking my Shiny app. The app was failing in writing file names, so while I don‚Äôt know exactly why that is, I do have a sense that file names often don‚Äôt like crazy characters.\nFinally, one more thing I need to do to improve my Shiny app is fix some directory issues. Currently I can only run my Shiny app when I highlight all the code and select run. If I try to run it from the console, it can‚Äôt find the correct directory to put the new post in. I suspect this has something to do with how the working directory is determined.\nUntil next time friends!"
  },
  {
    "objectID": "posts/2024-10-06-the-quest--energy--security--and-the-remaking-of-the-modern-world-/index.html",
    "href": "posts/2024-10-06-the-quest--energy--security--and-the-remaking-of-the-modern-world-/index.html",
    "title": "The Quest: Energy, Security, and the Remaking of the Modern World",
    "section": "",
    "text": "The past is just behind us\nMy father told me recently that he was the first generation of our family to never use horses on the farm. He was relaying a story about how in the rafters of one of the buildings on the family farm, we have a horse sleigh. He does not know anything how it was used and would not know how to attach horses to it even if he had the gear and horses. I actually doubt this given how mechanically inclined my father is, I think given all the components and some time, he would likely be able to cobble it all together quite well.\nMy grandfather was born in Iowa in 1915 and used horses as a child on the farm. I do not know when and what type of tractors first arrived on the farm in our little spot of central Iowa. I do know that after returning from serving in Europe after World War II my grandfather had some sort of coupon that allowed him to purchase a tractor, which was a boon to him and his family. He lived in the larger but nearby town and worked as a carpenter for some time before returning to take over the family farm, where I grew up.\nMy grandfather sadly died at age 70 in 1986 when I was only four months old, so I have no memory of him and only a few pictures of us together.\nHere we have a seismic event, historically speaking, the mechanization of farming‚Äìand in two generations‚Äìwe have a complete rupture with the prior way of farming, which presumably more closely resembled the prior 1000 years of farming by an order of magnitude with what came after following that debut of the tractor. Lost to me are also the stories of how my greatNth grandparents navigated the transition from farming in West/Central Europe to the Midwest of the United States.\nHere on our 2 acre home in Georgia we have a small, useful lawn tractor.\n\n\n\nOur Cub Cadet lawn tractor with another delightfully useful tool: a wagon.\n\n\nThe usefulness of this little device is huge, and we rarely use it for mowing‚Äìa true American pastime. I am time poor these days, so I pay someone to mow so I can spend time doing landscaping and gardening work, which is work I both enjoy and do not want to outsource as I love the experimentation and gradual process to change our grass lawn into a more complicated space for activities beyond merely mowing.\nI imagine my grandmothers and grandfathers for time immemorial cultivating family gardens or larger areas with nothing but their own power, hand tools, and, if they were lucky, some draft animals, and I reflect upon the tools and access to exploitable energy I have today.\nYergin‚Äôs The Quest: Energy, Security, and the Remaking of the Modern World was a good book especially with regards to understanding the incentives behind ‚Äúalternative‚Äù energy policy in the 20th and 21st century, but it did not reorder my world view and understanding of history the way his prior book The Prize did. A bit rich to ask for that level of impact twice. I think a more accessible book with material from The Prize and this book could be hewn from the source material to successfully transmit to any reasonably curious middle schooler in the United States how profound our access to energy has remade the world and our lives."
  },
  {
    "objectID": "posts/2025-11-22-holiday-kitchen-tips/index.html",
    "href": "posts/2025-11-22-holiday-kitchen-tips/index.html",
    "title": "Holiday Kitchen Tips",
    "section": "",
    "text": "Before Thanksgiving\nShelf stable food accumulates. It fills the nooks and crannies of a kitchen and pantry. How do you end up with a 5 extra gelatin packets, two different kinds of SPAM, and probably 4 different kinds of jams and preserves, etc?\nA weekend or two before Thanksgiving I set aside time to prepare the kitchen for the busy stretch of cooking between Thanksgiving, Christmas, and New Year‚Äôs.\nOver the year I collect extra boxes of pasta, jams, gelatin pouches, random canned items, and canned fish. As I prepare to cook for the holidays, this is a great time to make use of things that I already have in the kitchen, remove clutter, reconsider how I organize the kitchen, and complete an inventory to avoid frantic dashes to the store for cream of tartar on the eve of some major holiday.\n\n\nTasks\n\nDo a deep clean of the kitchen. Don‚Äôt open the cupboards yet! Make sure you have plenty of clean space on your counters and tables.\nCollect items from the kitchen you haven‚Äôt used in the past year and consider donating them or gifting them to someone who would find them useful. If you aren‚Äôt sure, designate a box as a holding center, place the items in there, and if you haven‚Äôt used them in another 3 months, you know you don‚Äôt need them. If you are newly inspired by an item, incorporate it into your cooking routine. Either get more space or a new kitchen toy‚Äìwin, win!\nNow in a clean, empty kitchen pull out your shelf stable goods and group them into reasonable categories (canned veggies together, pasta together etc.). As you do this, note what organization has and has not worked for you. Do you have 3 jars of paprika and no baking soda? Can reach items you use frequently or do you have to use a step stool to grab those items? Is it a pain to keep nuts in one spot? Are you eating your nuts so slowly they have gone off?\nClean out any boxes or other storage items. Would you benefit from either a smaller inventory or do you need to add a few more bins to organize your nuts and dried fruits in a more sane fashion? Take note of what might help the kitchen function better. A few $2 dollar bins can tame the pasta madness or grain chaos.\nDiscard any items that are not worth saving. Check that pantry stables like flour, sugar, spices, etc are sufficient for the extra baking and cooking you will be doing. Add items to your shopping list.\nUse the items you have in your next week of cooking or even as part of the upcoming holiday cooking! Ask a friend if they need 3 cans of pineapple juice. Or look up a new punch recipe if to see how you could use them for your new favorite holiday drink. I don‚Äôt recommend trying out new dishes on guests at holidays because it can be stressful cooking something you haven‚Äôt ever made before and disappointing if it doesn‚Äôt taste good, so consider being adventurous beforehand. I often don‚Äôt take this advice, but I am never unhappy when I do take this advice. For Christmas 2024 I made an elaborate salmon and rice dish that was wrapped in a sheet of dough. I didn‚Äôt know the importance of lamination for that type of dough, so my first attempt at the recipe with a cheap cabbage filling the week before saved Christmas dinner from a very bad crust.\nOrder or run out and get those organizing items you think you need. You can‚Äôt believe how much $20 of simple bins will improve you kitchen life.\nIf you haven‚Äôt already, take a marker plus/minus some masking tape to date items, so you know when you opened things or when they expire if not in the original packaging. Commit yourself to the habit of doing this when you get items or open them in the first place. This is even more important for fridge items.\nPlace everything back and think about where items show live now. What needs to be easily grabbed, what can be put on top shelves for visibility (eg a spare ketchup and jams) that you can get the step stool for but won‚Äôt be annoyed at the extra 15 steps of movement to get an item you need.\nGo forth and make lovely meals!"
  }
]